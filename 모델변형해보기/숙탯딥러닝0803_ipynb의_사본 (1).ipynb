{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "9joVFyA6sBNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "import torch\n",
        "import PIL"
      ],
      "metadata": {
        "id": "2LlERWIWEbyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VJFTQuNFkCa"
      },
      "outputs": [],
      "source": [
        "dir_path=\"/content/drive/MyDrive/2기 딥러닝 프로젝트/train\"\n",
        "labels = ['Closed', 'Open']\n",
        "x_data = []\n",
        "y_data = []\n",
        "for label in labels:\n",
        "   path = os.path.join(dir_path, label)\n",
        "   class_num = labels.index(label)\n",
        "   import torchvision.transforms as transforms\n",
        "   tf = transforms.ToTensor()\n",
        "   for img in os.listdir(path): # closed 폴더 안에 _1.jpg, open 폴더 안에 1.jpg \n",
        "       paths = os.path.join(path, img)\n",
        "       img =  PIL.Image.open(paths)\n",
        "       re_img = img.resize((64,64))\n",
        "       re_img = tf(re_img)\n",
        "       re_img = re_img.tolist()\n",
        "       if len(re_img) == 3:\n",
        "         x_data.append(re_img)\n",
        "         y_data.append(class_num)\n",
        "\n",
        "x_data = torch.tensor(x_data)\n",
        "y_data = torch.tensor(y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "자꾸 이런 expected sequence of length 3 at dim 1 (got 4) 오류가 나서\n",
        "\n",
        "if len(re_img) == 3: 코드를 추가해주었고 이걸 하고 나니까 원래는 x shape이 1451이었는데 1449로 줄어들었다 아마 2개의 x_data의 shape이 다른 사진들과 달랐던 것 같다"
      ],
      "metadata": {
        "id": "OVG7Gt0NrBVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07RzMtRE8tvr",
        "outputId": "23052e70-dd1c-4bdc-8986-77d5d6a7e210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1449, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oT-WZVn8v0m",
        "outputId": "c018fe3d-f96d-48eb-c8bc-fb01564ab5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1449])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_data = np.array(y_data)\n",
        "y_data = torch.tensor(y_data)\n",
        "y_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LF-_xWgIhnw",
        "outputId": "2b6ba9db-2848-4e21-ed3c-0f8cb20fe5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1449])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "4UImVH3N85wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LagbrK0JBcep",
        "outputId": "d06f76fc-0991-43c8-c1fe-3adf4d62f7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1159, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md2YgGRAgq1X",
        "outputId": "69d14bcb-95dc-47a3-b96a-920be1e0f219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1159])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **train**"
      ],
      "metadata": {
        "id": "yzpqlc4q0F6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "K-FZlyzeamkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(4096, 512) \n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = x.reshape(-1, 4096)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NgSaPWjrZ2pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.ones([1,3,64,64])\n",
        "conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "output1 = conv1(x)\n",
        "print(output1.shape)\n",
        "x1 = F.max_pool2d(F.relu(output1),2)\n",
        "print(x1.shape)\n",
        "conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "output2 = conv2(x1)\n",
        "print(output2.shape)\n",
        "x2 = F.max_pool2d(F.relu(output2), 2)\n",
        "print(x2.shape)\n",
        "conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "output3 = conv3(x2)\n",
        "print(output3.shape)\n",
        "x3 = F.max_pool2d(F.relu(output3), 2)\n",
        "print(x3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It9ZArZXQntW",
        "outputId": "f736ce80-16ce-47d4-b088-b802188c971b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 64, 64])\n",
            "torch.Size([1, 16, 32, 32])\n",
            "torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 32, 16, 16])\n",
            "torch.Size([1, 64, 16, 16])\n",
            "torch.Size([1, 64, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "x = torch.ones(1, 3,64,64)\n",
        "x = x.float()\n",
        "output = model(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sfrS83Hyiuh",
        "outputId": "56f7d3ad-b730-4800-def4-7c6c55ccfb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.to('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "fyL-8gqxZ4SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum / y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "KYUTmbWtJLBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i,data in enumerate(x_train, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to('cuda')\n",
        "        labels = y_train.to('cuda')\n",
        "\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        #print(\"intpus_1 shape: \",input_1.shape)\n",
        "        #print(\"outputs shape: \",outputs.shape)\n",
        "        #print(\"labels shape\",labels.shape)\n",
        "         #labels = labels.view(len(labels),-1)\n",
        "        loss = criterion(outputs, k)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += accuracy(outputs, k)\n",
        "\n",
        "        if i % 80 == 79:\n",
        "            print('epoch: [%d/%d] train_loss: %.5f train_acc: %.5f' % (\n",
        "                epoch + 1, epochs, running_loss / 80, running_acc / 80))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"learning finish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o8FzWGBnley",
        "outputId": "9863bcf8-a902-4317-c0ac-216308907f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/50] train_loss: 0.69876 train_acc: 48.75000\n",
            "epoch: [1/50] train_loss: 0.69525 train_acc: 97.50000\n",
            "epoch: [1/50] train_loss: 0.68318 train_acc: 156.25000\n",
            "epoch: [1/50] train_loss: 0.67837 train_acc: 220.00000\n",
            "epoch: [1/50] train_loss: 0.65744 train_acc: 287.50000\n",
            "epoch: [1/50] train_loss: 0.56549 train_acc: 368.75000\n",
            "epoch: [1/50] train_loss: 0.46055 train_acc: 451.25000\n",
            "epoch: [1/50] train_loss: 0.31957 train_acc: 540.00000\n",
            "epoch: [1/50] train_loss: 0.25567 train_acc: 630.00000\n",
            "epoch: [1/50] train_loss: 0.22548 train_acc: 722.50000\n",
            "epoch: [1/50] train_loss: 0.13178 train_acc: 820.00000\n",
            "epoch: [1/50] train_loss: 0.09688 train_acc: 916.25000\n",
            "epoch: [1/50] train_loss: 0.16200 train_acc: 1007.50000\n",
            "epoch: [1/50] train_loss: 0.19212 train_acc: 1098.75000\n",
            "epoch: [2/50] train_loss: 0.18044 train_acc: 96.25000\n",
            "epoch: [2/50] train_loss: 0.30371 train_acc: 185.00000\n",
            "epoch: [2/50] train_loss: 0.15079 train_acc: 278.75000\n",
            "epoch: [2/50] train_loss: 0.17988 train_acc: 372.50000\n",
            "epoch: [2/50] train_loss: 0.08875 train_acc: 470.00000\n",
            "epoch: [2/50] train_loss: 0.19252 train_acc: 563.75000\n",
            "epoch: [2/50] train_loss: 0.11792 train_acc: 658.75000\n",
            "epoch: [2/50] train_loss: 0.12487 train_acc: 755.00000\n",
            "epoch: [2/50] train_loss: 0.09890 train_acc: 853.75000\n",
            "epoch: [2/50] train_loss: 0.14051 train_acc: 948.75000\n",
            "epoch: [2/50] train_loss: 0.08989 train_acc: 1046.25000\n",
            "epoch: [2/50] train_loss: 0.05324 train_acc: 1145.00000\n",
            "epoch: [2/50] train_loss: 0.08077 train_acc: 1243.75000\n",
            "epoch: [2/50] train_loss: 0.09392 train_acc: 1338.75000\n",
            "epoch: [3/50] train_loss: 0.16708 train_acc: 96.25000\n",
            "epoch: [3/50] train_loss: 0.24182 train_acc: 186.25000\n",
            "epoch: [3/50] train_loss: 0.10435 train_acc: 281.25000\n",
            "epoch: [3/50] train_loss: 0.12631 train_acc: 376.25000\n",
            "epoch: [3/50] train_loss: 0.05420 train_acc: 475.00000\n",
            "epoch: [3/50] train_loss: 0.15810 train_acc: 568.75000\n",
            "epoch: [3/50] train_loss: 0.07916 train_acc: 666.25000\n",
            "epoch: [3/50] train_loss: 0.09535 train_acc: 762.50000\n",
            "epoch: [3/50] train_loss: 0.07262 train_acc: 860.00000\n",
            "epoch: [3/50] train_loss: 0.10469 train_acc: 956.25000\n",
            "epoch: [3/50] train_loss: 0.08782 train_acc: 1055.00000\n",
            "epoch: [3/50] train_loss: 0.04340 train_acc: 1153.75000\n",
            "epoch: [3/50] train_loss: 0.06928 train_acc: 1252.50000\n",
            "epoch: [3/50] train_loss: 0.04856 train_acc: 1352.50000\n",
            "epoch: [4/50] train_loss: 0.15586 train_acc: 96.25000\n",
            "epoch: [4/50] train_loss: 0.19600 train_acc: 190.00000\n",
            "epoch: [4/50] train_loss: 0.08216 train_acc: 288.75000\n",
            "epoch: [4/50] train_loss: 0.08927 train_acc: 386.25000\n",
            "epoch: [4/50] train_loss: 0.03585 train_acc: 485.00000\n",
            "epoch: [4/50] train_loss: 0.14275 train_acc: 578.75000\n",
            "epoch: [4/50] train_loss: 0.05827 train_acc: 677.50000\n",
            "epoch: [4/50] train_loss: 0.07962 train_acc: 775.00000\n",
            "epoch: [4/50] train_loss: 0.05724 train_acc: 873.75000\n",
            "epoch: [4/50] train_loss: 0.08683 train_acc: 971.25000\n",
            "epoch: [4/50] train_loss: 0.09032 train_acc: 1070.00000\n",
            "epoch: [4/50] train_loss: 0.04139 train_acc: 1167.50000\n",
            "epoch: [4/50] train_loss: 0.05649 train_acc: 1266.25000\n",
            "epoch: [4/50] train_loss: 0.02951 train_acc: 1366.25000\n",
            "epoch: [5/50] train_loss: 0.14691 train_acc: 96.25000\n",
            "epoch: [5/50] train_loss: 0.16858 train_acc: 192.50000\n",
            "epoch: [5/50] train_loss: 0.07185 train_acc: 291.25000\n",
            "epoch: [5/50] train_loss: 0.06659 train_acc: 390.00000\n",
            "epoch: [5/50] train_loss: 0.02948 train_acc: 490.00000\n",
            "epoch: [5/50] train_loss: 0.12268 train_acc: 583.75000\n",
            "epoch: [5/50] train_loss: 0.04820 train_acc: 682.50000\n",
            "epoch: [5/50] train_loss: 0.05655 train_acc: 781.25000\n",
            "epoch: [5/50] train_loss: 0.04583 train_acc: 880.00000\n",
            "epoch: [5/50] train_loss: 0.07103 train_acc: 977.50000\n",
            "epoch: [5/50] train_loss: 0.09262 train_acc: 1076.25000\n",
            "epoch: [5/50] train_loss: 0.04524 train_acc: 1173.75000\n",
            "epoch: [5/50] train_loss: 0.04886 train_acc: 1272.50000\n",
            "epoch: [5/50] train_loss: 0.02066 train_acc: 1372.50000\n",
            "epoch: [6/50] train_loss: 0.13078 train_acc: 96.25000\n",
            "epoch: [6/50] train_loss: 0.14594 train_acc: 191.25000\n",
            "epoch: [6/50] train_loss: 0.06789 train_acc: 290.00000\n",
            "epoch: [6/50] train_loss: 0.04827 train_acc: 390.00000\n",
            "epoch: [6/50] train_loss: 0.02834 train_acc: 488.75000\n",
            "epoch: [6/50] train_loss: 0.12205 train_acc: 583.75000\n",
            "epoch: [6/50] train_loss: 0.03462 train_acc: 682.50000\n",
            "epoch: [6/50] train_loss: 0.03520 train_acc: 782.50000\n",
            "epoch: [6/50] train_loss: 0.03857 train_acc: 881.25000\n",
            "epoch: [6/50] train_loss: 0.05660 train_acc: 978.75000\n",
            "epoch: [6/50] train_loss: 0.08741 train_acc: 1077.50000\n",
            "epoch: [6/50] train_loss: 0.04297 train_acc: 1175.00000\n",
            "epoch: [6/50] train_loss: 0.03958 train_acc: 1273.75000\n",
            "epoch: [6/50] train_loss: 0.01592 train_acc: 1373.75000\n",
            "epoch: [7/50] train_loss: 0.10882 train_acc: 96.25000\n",
            "epoch: [7/50] train_loss: 0.13042 train_acc: 191.25000\n",
            "epoch: [7/50] train_loss: 0.05979 train_acc: 290.00000\n",
            "epoch: [7/50] train_loss: 0.03602 train_acc: 390.00000\n",
            "epoch: [7/50] train_loss: 0.02967 train_acc: 488.75000\n",
            "epoch: [7/50] train_loss: 0.13470 train_acc: 585.00000\n",
            "epoch: [7/50] train_loss: 0.02843 train_acc: 685.00000\n",
            "epoch: [7/50] train_loss: 0.02444 train_acc: 785.00000\n",
            "epoch: [7/50] train_loss: 0.03340 train_acc: 885.00000\n",
            "epoch: [7/50] train_loss: 0.04080 train_acc: 982.50000\n",
            "epoch: [7/50] train_loss: 0.07875 train_acc: 1081.25000\n",
            "epoch: [7/50] train_loss: 0.03335 train_acc: 1178.75000\n",
            "epoch: [7/50] train_loss: 0.03350 train_acc: 1277.50000\n",
            "epoch: [7/50] train_loss: 0.01289 train_acc: 1377.50000\n",
            "epoch: [8/50] train_loss: 0.09055 train_acc: 96.25000\n",
            "epoch: [8/50] train_loss: 0.12041 train_acc: 191.25000\n",
            "epoch: [8/50] train_loss: 0.04762 train_acc: 290.00000\n",
            "epoch: [8/50] train_loss: 0.03023 train_acc: 390.00000\n",
            "epoch: [8/50] train_loss: 0.02625 train_acc: 488.75000\n",
            "epoch: [8/50] train_loss: 0.10630 train_acc: 586.25000\n",
            "epoch: [8/50] train_loss: 0.02159 train_acc: 686.25000\n",
            "epoch: [8/50] train_loss: 0.01786 train_acc: 786.25000\n",
            "epoch: [8/50] train_loss: 0.02899 train_acc: 886.25000\n",
            "epoch: [8/50] train_loss: 0.02936 train_acc: 985.00000\n",
            "epoch: [8/50] train_loss: 0.06447 train_acc: 1083.75000\n",
            "epoch: [8/50] train_loss: 0.02286 train_acc: 1182.50000\n",
            "epoch: [8/50] train_loss: 0.01968 train_acc: 1281.25000\n",
            "epoch: [8/50] train_loss: 0.01033 train_acc: 1381.25000\n",
            "epoch: [9/50] train_loss: 0.07520 train_acc: 97.50000\n",
            "epoch: [9/50] train_loss: 0.09551 train_acc: 193.75000\n",
            "epoch: [9/50] train_loss: 0.03502 train_acc: 292.50000\n",
            "epoch: [9/50] train_loss: 0.02597 train_acc: 392.50000\n",
            "epoch: [9/50] train_loss: 0.02811 train_acc: 491.25000\n",
            "epoch: [9/50] train_loss: 0.09139 train_acc: 588.75000\n",
            "epoch: [9/50] train_loss: 0.01861 train_acc: 688.75000\n",
            "epoch: [9/50] train_loss: 0.01262 train_acc: 788.75000\n",
            "epoch: [9/50] train_loss: 0.02399 train_acc: 888.75000\n",
            "epoch: [9/50] train_loss: 0.02463 train_acc: 987.50000\n",
            "epoch: [9/50] train_loss: 0.05341 train_acc: 1086.25000\n",
            "epoch: [9/50] train_loss: 0.01852 train_acc: 1185.00000\n",
            "epoch: [9/50] train_loss: 0.01361 train_acc: 1285.00000\n",
            "epoch: [9/50] train_loss: 0.00932 train_acc: 1385.00000\n",
            "epoch: [10/50] train_loss: 0.06426 train_acc: 98.75000\n",
            "epoch: [10/50] train_loss: 0.06230 train_acc: 196.25000\n",
            "epoch: [10/50] train_loss: 0.03033 train_acc: 295.00000\n",
            "epoch: [10/50] train_loss: 0.02345 train_acc: 395.00000\n",
            "epoch: [10/50] train_loss: 0.02261 train_acc: 493.75000\n",
            "epoch: [10/50] train_loss: 0.06851 train_acc: 591.25000\n",
            "epoch: [10/50] train_loss: 0.01462 train_acc: 691.25000\n",
            "epoch: [10/50] train_loss: 0.00848 train_acc: 791.25000\n",
            "epoch: [10/50] train_loss: 0.02043 train_acc: 891.25000\n",
            "epoch: [10/50] train_loss: 0.02287 train_acc: 990.00000\n",
            "epoch: [10/50] train_loss: 0.04214 train_acc: 1088.75000\n",
            "epoch: [10/50] train_loss: 0.00625 train_acc: 1188.75000\n",
            "epoch: [10/50] train_loss: 0.01011 train_acc: 1288.75000\n",
            "epoch: [10/50] train_loss: 0.00695 train_acc: 1388.75000\n",
            "epoch: [11/50] train_loss: 0.06235 train_acc: 98.75000\n",
            "epoch: [11/50] train_loss: 0.03742 train_acc: 197.50000\n",
            "epoch: [11/50] train_loss: 0.02045 train_acc: 297.50000\n",
            "epoch: [11/50] train_loss: 0.02973 train_acc: 396.25000\n",
            "epoch: [11/50] train_loss: 0.02464 train_acc: 495.00000\n",
            "epoch: [11/50] train_loss: 0.06504 train_acc: 593.75000\n",
            "epoch: [11/50] train_loss: 0.01481 train_acc: 693.75000\n",
            "epoch: [11/50] train_loss: 0.00685 train_acc: 793.75000\n",
            "epoch: [11/50] train_loss: 0.01953 train_acc: 892.50000\n",
            "epoch: [11/50] train_loss: 0.01867 train_acc: 991.25000\n",
            "epoch: [11/50] train_loss: 0.03227 train_acc: 1090.00000\n",
            "epoch: [11/50] train_loss: 0.00370 train_acc: 1190.00000\n",
            "epoch: [11/50] train_loss: 0.01226 train_acc: 1290.00000\n",
            "epoch: [11/50] train_loss: 0.00608 train_acc: 1390.00000\n",
            "epoch: [12/50] train_loss: 0.05821 train_acc: 98.75000\n",
            "epoch: [12/50] train_loss: 0.03501 train_acc: 197.50000\n",
            "epoch: [12/50] train_loss: 0.01442 train_acc: 297.50000\n",
            "epoch: [12/50] train_loss: 0.04779 train_acc: 396.25000\n",
            "epoch: [12/50] train_loss: 0.01977 train_acc: 495.00000\n",
            "epoch: [12/50] train_loss: 0.05622 train_acc: 592.50000\n",
            "epoch: [12/50] train_loss: 0.01849 train_acc: 692.50000\n",
            "epoch: [12/50] train_loss: 0.00560 train_acc: 792.50000\n",
            "epoch: [12/50] train_loss: 0.01329 train_acc: 892.50000\n",
            "epoch: [12/50] train_loss: 0.02060 train_acc: 991.25000\n",
            "epoch: [12/50] train_loss: 0.01282 train_acc: 1091.25000\n",
            "epoch: [12/50] train_loss: 0.00692 train_acc: 1191.25000\n",
            "epoch: [12/50] train_loss: 0.00656 train_acc: 1291.25000\n",
            "epoch: [12/50] train_loss: 0.00524 train_acc: 1391.25000\n",
            "epoch: [13/50] train_loss: 0.05102 train_acc: 98.75000\n",
            "epoch: [13/50] train_loss: 0.02859 train_acc: 197.50000\n",
            "epoch: [13/50] train_loss: 0.02145 train_acc: 296.25000\n",
            "epoch: [13/50] train_loss: 0.03815 train_acc: 395.00000\n",
            "epoch: [13/50] train_loss: 0.03549 train_acc: 492.50000\n",
            "epoch: [13/50] train_loss: 0.06766 train_acc: 590.00000\n",
            "epoch: [13/50] train_loss: 0.01535 train_acc: 690.00000\n",
            "epoch: [13/50] train_loss: 0.00259 train_acc: 790.00000\n",
            "epoch: [13/50] train_loss: 0.01133 train_acc: 890.00000\n",
            "epoch: [13/50] train_loss: 0.03270 train_acc: 988.75000\n",
            "epoch: [13/50] train_loss: 0.01150 train_acc: 1088.75000\n",
            "epoch: [13/50] train_loss: 0.00222 train_acc: 1188.75000\n",
            "epoch: [13/50] train_loss: 0.00696 train_acc: 1288.75000\n",
            "epoch: [13/50] train_loss: 0.00175 train_acc: 1388.75000\n",
            "epoch: [14/50] train_loss: 0.03812 train_acc: 98.75000\n",
            "epoch: [14/50] train_loss: 0.03401 train_acc: 197.50000\n",
            "epoch: [14/50] train_loss: 0.04271 train_acc: 296.25000\n",
            "epoch: [14/50] train_loss: 0.02648 train_acc: 395.00000\n",
            "epoch: [14/50] train_loss: 0.01719 train_acc: 495.00000\n",
            "epoch: [14/50] train_loss: 0.06910 train_acc: 592.50000\n",
            "epoch: [14/50] train_loss: 0.01364 train_acc: 692.50000\n",
            "epoch: [14/50] train_loss: 0.00801 train_acc: 792.50000\n",
            "epoch: [14/50] train_loss: 0.02149 train_acc: 891.25000\n",
            "epoch: [14/50] train_loss: 0.02537 train_acc: 990.00000\n",
            "epoch: [14/50] train_loss: 0.00604 train_acc: 1090.00000\n",
            "epoch: [14/50] train_loss: 0.00112 train_acc: 1190.00000\n",
            "epoch: [14/50] train_loss: 0.00225 train_acc: 1290.00000\n",
            "epoch: [14/50] train_loss: 0.00315 train_acc: 1390.00000\n",
            "epoch: [15/50] train_loss: 0.04982 train_acc: 98.75000\n",
            "epoch: [15/50] train_loss: 0.02779 train_acc: 198.75000\n",
            "epoch: [15/50] train_loss: 0.02994 train_acc: 296.25000\n",
            "epoch: [15/50] train_loss: 0.05605 train_acc: 393.75000\n",
            "epoch: [15/50] train_loss: 0.04197 train_acc: 491.25000\n",
            "epoch: [15/50] train_loss: 0.07859 train_acc: 590.00000\n",
            "epoch: [15/50] train_loss: 0.00846 train_acc: 690.00000\n",
            "epoch: [15/50] train_loss: 0.00742 train_acc: 790.00000\n",
            "epoch: [15/50] train_loss: 0.01000 train_acc: 890.00000\n",
            "epoch: [15/50] train_loss: 0.02739 train_acc: 988.75000\n",
            "epoch: [15/50] train_loss: 0.01305 train_acc: 1087.50000\n",
            "epoch: [15/50] train_loss: 0.00219 train_acc: 1187.50000\n",
            "epoch: [15/50] train_loss: 0.00556 train_acc: 1287.50000\n",
            "epoch: [15/50] train_loss: 0.00308 train_acc: 1387.50000\n",
            "epoch: [16/50] train_loss: 0.03067 train_acc: 98.75000\n",
            "epoch: [16/50] train_loss: 0.02747 train_acc: 197.50000\n",
            "epoch: [16/50] train_loss: 0.02412 train_acc: 296.25000\n",
            "epoch: [16/50] train_loss: 0.01470 train_acc: 396.25000\n",
            "epoch: [16/50] train_loss: 0.00506 train_acc: 496.25000\n",
            "epoch: [16/50] train_loss: 0.03660 train_acc: 595.00000\n",
            "epoch: [16/50] train_loss: 0.00946 train_acc: 695.00000\n",
            "epoch: [16/50] train_loss: 0.00357 train_acc: 795.00000\n",
            "epoch: [16/50] train_loss: 0.01321 train_acc: 895.00000\n",
            "epoch: [16/50] train_loss: 0.02793 train_acc: 993.75000\n",
            "epoch: [16/50] train_loss: 0.00850 train_acc: 1093.75000\n",
            "epoch: [16/50] train_loss: 0.00078 train_acc: 1193.75000\n",
            "epoch: [16/50] train_loss: 0.00521 train_acc: 1293.75000\n",
            "epoch: [16/50] train_loss: 0.00184 train_acc: 1393.75000\n",
            "epoch: [17/50] train_loss: 0.01245 train_acc: 100.00000\n",
            "epoch: [17/50] train_loss: 0.01874 train_acc: 198.75000\n",
            "epoch: [17/50] train_loss: 0.01386 train_acc: 298.75000\n",
            "epoch: [17/50] train_loss: 0.04378 train_acc: 397.50000\n",
            "epoch: [17/50] train_loss: 0.00233 train_acc: 497.50000\n",
            "epoch: [17/50] train_loss: 0.01925 train_acc: 596.25000\n",
            "epoch: [17/50] train_loss: 0.00630 train_acc: 696.25000\n",
            "epoch: [17/50] train_loss: 0.00155 train_acc: 796.25000\n",
            "epoch: [17/50] train_loss: 0.00837 train_acc: 896.25000\n",
            "epoch: [17/50] train_loss: 0.01641 train_acc: 996.25000\n",
            "epoch: [17/50] train_loss: 0.00219 train_acc: 1096.25000\n",
            "epoch: [17/50] train_loss: 0.00146 train_acc: 1196.25000\n",
            "epoch: [17/50] train_loss: 0.00084 train_acc: 1296.25000\n",
            "epoch: [17/50] train_loss: 0.00096 train_acc: 1396.25000\n",
            "epoch: [18/50] train_loss: 0.02114 train_acc: 98.75000\n",
            "epoch: [18/50] train_loss: 0.01974 train_acc: 197.50000\n",
            "epoch: [18/50] train_loss: 0.03220 train_acc: 296.25000\n",
            "epoch: [18/50] train_loss: 0.04248 train_acc: 392.50000\n",
            "epoch: [18/50] train_loss: 0.00441 train_acc: 492.50000\n",
            "epoch: [18/50] train_loss: 0.12135 train_acc: 590.00000\n",
            "epoch: [18/50] train_loss: 0.00967 train_acc: 690.00000\n",
            "epoch: [18/50] train_loss: 0.00299 train_acc: 790.00000\n",
            "epoch: [18/50] train_loss: 0.00396 train_acc: 890.00000\n",
            "epoch: [18/50] train_loss: 0.01069 train_acc: 990.00000\n",
            "epoch: [18/50] train_loss: 0.00475 train_acc: 1090.00000\n",
            "epoch: [18/50] train_loss: 0.00141 train_acc: 1190.00000\n",
            "epoch: [18/50] train_loss: 0.00152 train_acc: 1290.00000\n",
            "epoch: [18/50] train_loss: 0.00112 train_acc: 1390.00000\n",
            "epoch: [19/50] train_loss: 0.00652 train_acc: 100.00000\n",
            "epoch: [19/50] train_loss: 0.01325 train_acc: 198.75000\n",
            "epoch: [19/50] train_loss: 0.01802 train_acc: 297.50000\n",
            "epoch: [19/50] train_loss: 0.07338 train_acc: 395.00000\n",
            "epoch: [19/50] train_loss: 0.00482 train_acc: 495.00000\n",
            "epoch: [19/50] train_loss: 0.02556 train_acc: 593.75000\n",
            "epoch: [19/50] train_loss: 0.01441 train_acc: 692.50000\n",
            "epoch: [19/50] train_loss: 0.00188 train_acc: 792.50000\n",
            "epoch: [19/50] train_loss: 0.00190 train_acc: 892.50000\n",
            "epoch: [19/50] train_loss: 0.01503 train_acc: 991.25000\n",
            "epoch: [19/50] train_loss: 0.02255 train_acc: 1090.00000\n",
            "epoch: [19/50] train_loss: 0.00269 train_acc: 1190.00000\n",
            "epoch: [19/50] train_loss: 0.01162 train_acc: 1290.00000\n",
            "epoch: [19/50] train_loss: 0.00149 train_acc: 1390.00000\n",
            "epoch: [20/50] train_loss: 0.00750 train_acc: 100.00000\n",
            "epoch: [20/50] train_loss: 0.00907 train_acc: 200.00000\n",
            "epoch: [20/50] train_loss: 0.00346 train_acc: 300.00000\n",
            "epoch: [20/50] train_loss: 0.00996 train_acc: 400.00000\n",
            "epoch: [20/50] train_loss: 0.00479 train_acc: 500.00000\n",
            "epoch: [20/50] train_loss: 0.03433 train_acc: 597.50000\n",
            "epoch: [20/50] train_loss: 0.02100 train_acc: 696.25000\n",
            "epoch: [20/50] train_loss: 0.00077 train_acc: 796.25000\n",
            "epoch: [20/50] train_loss: 0.00486 train_acc: 896.25000\n",
            "epoch: [20/50] train_loss: 0.01119 train_acc: 995.00000\n",
            "epoch: [20/50] train_loss: 0.00157 train_acc: 1095.00000\n",
            "epoch: [20/50] train_loss: 0.00079 train_acc: 1195.00000\n",
            "epoch: [20/50] train_loss: 0.00108 train_acc: 1295.00000\n",
            "epoch: [20/50] train_loss: 0.00044 train_acc: 1395.00000\n",
            "epoch: [21/50] train_loss: 0.00716 train_acc: 100.00000\n",
            "epoch: [21/50] train_loss: 0.00308 train_acc: 200.00000\n",
            "epoch: [21/50] train_loss: 0.00139 train_acc: 300.00000\n",
            "epoch: [21/50] train_loss: 0.00673 train_acc: 400.00000\n",
            "epoch: [21/50] train_loss: 0.00445 train_acc: 500.00000\n",
            "epoch: [21/50] train_loss: 0.01140 train_acc: 600.00000\n",
            "epoch: [21/50] train_loss: 0.00815 train_acc: 700.00000\n",
            "epoch: [21/50] train_loss: 0.08400 train_acc: 796.25000\n",
            "epoch: [21/50] train_loss: 0.03636 train_acc: 893.75000\n",
            "epoch: [21/50] train_loss: 0.01109 train_acc: 993.75000\n",
            "epoch: [21/50] train_loss: 0.00499 train_acc: 1093.75000\n",
            "epoch: [21/50] train_loss: 0.00169 train_acc: 1193.75000\n",
            "epoch: [21/50] train_loss: 0.00140 train_acc: 1293.75000\n",
            "epoch: [21/50] train_loss: 0.00496 train_acc: 1393.75000\n",
            "epoch: [22/50] train_loss: 0.00541 train_acc: 100.00000\n",
            "epoch: [22/50] train_loss: 0.01294 train_acc: 198.75000\n",
            "epoch: [22/50] train_loss: 0.00289 train_acc: 298.75000\n",
            "epoch: [22/50] train_loss: 0.00612 train_acc: 398.75000\n",
            "epoch: [22/50] train_loss: 0.00122 train_acc: 498.75000\n",
            "epoch: [22/50] train_loss: 0.00015 train_acc: 598.75000\n",
            "epoch: [22/50] train_loss: 0.00398 train_acc: 698.75000\n",
            "epoch: [22/50] train_loss: 0.00011 train_acc: 798.75000\n",
            "epoch: [22/50] train_loss: 0.02645 train_acc: 896.25000\n",
            "epoch: [22/50] train_loss: 0.00925 train_acc: 996.25000\n",
            "epoch: [22/50] train_loss: 0.00137 train_acc: 1096.25000\n",
            "epoch: [22/50] train_loss: 0.00055 train_acc: 1196.25000\n",
            "epoch: [22/50] train_loss: 0.00382 train_acc: 1296.25000\n",
            "epoch: [22/50] train_loss: 0.00142 train_acc: 1396.25000\n",
            "epoch: [23/50] train_loss: 0.02468 train_acc: 97.50000\n",
            "epoch: [23/50] train_loss: 0.03319 train_acc: 195.00000\n",
            "epoch: [23/50] train_loss: 0.09797 train_acc: 292.50000\n",
            "epoch: [23/50] train_loss: 0.04084 train_acc: 390.00000\n",
            "epoch: [23/50] train_loss: 0.00520 train_acc: 490.00000\n",
            "epoch: [23/50] train_loss: 0.03701 train_acc: 588.75000\n",
            "epoch: [23/50] train_loss: 0.00663 train_acc: 688.75000\n",
            "epoch: [23/50] train_loss: 0.00251 train_acc: 788.75000\n",
            "epoch: [23/50] train_loss: 0.00141 train_acc: 888.75000\n",
            "epoch: [23/50] train_loss: 0.01691 train_acc: 987.50000\n",
            "epoch: [23/50] train_loss: 0.00215 train_acc: 1087.50000\n",
            "epoch: [23/50] train_loss: 0.00136 train_acc: 1187.50000\n",
            "epoch: [23/50] train_loss: 0.00058 train_acc: 1287.50000\n",
            "epoch: [23/50] train_loss: 0.00055 train_acc: 1387.50000\n",
            "epoch: [24/50] train_loss: 0.02788 train_acc: 98.75000\n",
            "epoch: [24/50] train_loss: 0.00926 train_acc: 198.75000\n",
            "epoch: [24/50] train_loss: 0.01630 train_acc: 297.50000\n",
            "epoch: [24/50] train_loss: 0.02036 train_acc: 396.25000\n",
            "epoch: [24/50] train_loss: 0.00639 train_acc: 496.25000\n",
            "epoch: [24/50] train_loss: 0.00202 train_acc: 596.25000\n",
            "epoch: [24/50] train_loss: 0.00074 train_acc: 696.25000\n",
            "epoch: [24/50] train_loss: 0.00007 train_acc: 796.25000\n",
            "epoch: [24/50] train_loss: 0.00628 train_acc: 896.25000\n",
            "epoch: [24/50] train_loss: 0.00547 train_acc: 996.25000\n",
            "epoch: [24/50] train_loss: 0.00143 train_acc: 1096.25000\n",
            "epoch: [24/50] train_loss: 0.00067 train_acc: 1196.25000\n",
            "epoch: [24/50] train_loss: 0.00028 train_acc: 1296.25000\n",
            "epoch: [24/50] train_loss: 0.00029 train_acc: 1396.25000\n",
            "epoch: [25/50] train_loss: 0.00139 train_acc: 100.00000\n",
            "epoch: [25/50] train_loss: 0.00852 train_acc: 200.00000\n",
            "epoch: [25/50] train_loss: 0.00049 train_acc: 300.00000\n",
            "epoch: [25/50] train_loss: 0.00165 train_acc: 400.00000\n",
            "epoch: [25/50] train_loss: 0.00514 train_acc: 500.00000\n",
            "epoch: [25/50] train_loss: 0.00765 train_acc: 600.00000\n",
            "epoch: [25/50] train_loss: 0.00139 train_acc: 700.00000\n",
            "epoch: [25/50] train_loss: 0.00014 train_acc: 800.00000\n",
            "epoch: [25/50] train_loss: 0.00229 train_acc: 900.00000\n",
            "epoch: [25/50] train_loss: 0.00160 train_acc: 1000.00000\n",
            "epoch: [25/50] train_loss: 0.00009 train_acc: 1100.00000\n",
            "epoch: [25/50] train_loss: 0.06041 train_acc: 1196.25000\n",
            "epoch: [25/50] train_loss: 0.22113 train_acc: 1292.50000\n",
            "epoch: [25/50] train_loss: 0.00299 train_acc: 1392.50000\n",
            "epoch: [26/50] train_loss: 0.00752 train_acc: 100.00000\n",
            "epoch: [26/50] train_loss: 0.01569 train_acc: 200.00000\n",
            "epoch: [26/50] train_loss: 0.00421 train_acc: 300.00000\n",
            "epoch: [26/50] train_loss: 0.01772 train_acc: 398.75000\n",
            "epoch: [26/50] train_loss: 0.00015 train_acc: 498.75000\n",
            "epoch: [26/50] train_loss: 0.00342 train_acc: 598.75000\n",
            "epoch: [26/50] train_loss: 0.00180 train_acc: 698.75000\n",
            "epoch: [26/50] train_loss: 0.00025 train_acc: 798.75000\n",
            "epoch: [26/50] train_loss: 0.00668 train_acc: 898.75000\n",
            "epoch: [26/50] train_loss: 0.03178 train_acc: 996.25000\n",
            "epoch: [26/50] train_loss: 0.00061 train_acc: 1096.25000\n",
            "epoch: [26/50] train_loss: 0.00029 train_acc: 1196.25000\n",
            "epoch: [26/50] train_loss: 0.00289 train_acc: 1296.25000\n",
            "epoch: [26/50] train_loss: 0.00046 train_acc: 1396.25000\n",
            "epoch: [27/50] train_loss: 0.00403 train_acc: 100.00000\n",
            "epoch: [27/50] train_loss: 0.01258 train_acc: 198.75000\n",
            "epoch: [27/50] train_loss: 0.00158 train_acc: 298.75000\n",
            "epoch: [27/50] train_loss: 0.00212 train_acc: 398.75000\n",
            "epoch: [27/50] train_loss: 0.00136 train_acc: 498.75000\n",
            "epoch: [27/50] train_loss: 0.00011 train_acc: 598.75000\n",
            "epoch: [27/50] train_loss: 0.00105 train_acc: 698.75000\n",
            "epoch: [27/50] train_loss: 0.00003 train_acc: 798.75000\n",
            "epoch: [27/50] train_loss: 0.00195 train_acc: 898.75000\n",
            "epoch: [27/50] train_loss: 0.00046 train_acc: 998.75000\n",
            "epoch: [27/50] train_loss: 0.00017 train_acc: 1098.75000\n",
            "epoch: [27/50] train_loss: 0.00598 train_acc: 1198.75000\n",
            "epoch: [27/50] train_loss: 0.00193 train_acc: 1298.75000\n",
            "epoch: [27/50] train_loss: 0.00087 train_acc: 1398.75000\n",
            "epoch: [28/50] train_loss: 0.00091 train_acc: 100.00000\n",
            "epoch: [28/50] train_loss: 0.00248 train_acc: 200.00000\n",
            "epoch: [28/50] train_loss: 0.00275 train_acc: 300.00000\n",
            "epoch: [28/50] train_loss: 0.00139 train_acc: 400.00000\n",
            "epoch: [28/50] train_loss: 0.00116 train_acc: 500.00000\n",
            "epoch: [28/50] train_loss: 0.00007 train_acc: 600.00000\n",
            "epoch: [28/50] train_loss: 0.00056 train_acc: 700.00000\n",
            "epoch: [28/50] train_loss: 0.00003 train_acc: 800.00000\n",
            "epoch: [28/50] train_loss: 0.00275 train_acc: 900.00000\n",
            "epoch: [28/50] train_loss: 0.00048 train_acc: 1000.00000\n",
            "epoch: [28/50] train_loss: 0.00010 train_acc: 1100.00000\n",
            "epoch: [28/50] train_loss: 0.00010 train_acc: 1200.00000\n",
            "epoch: [28/50] train_loss: 0.00221 train_acc: 1300.00000\n",
            "epoch: [28/50] train_loss: 0.00006 train_acc: 1400.00000\n",
            "epoch: [29/50] train_loss: 0.00167 train_acc: 100.00000\n",
            "epoch: [29/50] train_loss: 0.00035 train_acc: 200.00000\n",
            "epoch: [29/50] train_loss: 0.00236 train_acc: 300.00000\n",
            "epoch: [29/50] train_loss: 0.00163 train_acc: 400.00000\n",
            "epoch: [29/50] train_loss: 0.00117 train_acc: 500.00000\n",
            "epoch: [29/50] train_loss: 0.00030 train_acc: 600.00000\n",
            "epoch: [29/50] train_loss: 0.00039 train_acc: 700.00000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [29/50] train_loss: 0.00064 train_acc: 900.00000\n",
            "epoch: [29/50] train_loss: 0.00026 train_acc: 1000.00000\n",
            "epoch: [29/50] train_loss: 0.00007 train_acc: 1100.00000\n",
            "epoch: [29/50] train_loss: 0.00027 train_acc: 1200.00000\n",
            "epoch: [29/50] train_loss: 0.00008 train_acc: 1300.00000\n",
            "epoch: [29/50] train_loss: 0.00082 train_acc: 1400.00000\n",
            "epoch: [30/50] train_loss: 0.00075 train_acc: 100.00000\n",
            "epoch: [30/50] train_loss: 0.00065 train_acc: 200.00000\n",
            "epoch: [30/50] train_loss: 0.00038 train_acc: 300.00000\n",
            "epoch: [30/50] train_loss: 0.00076 train_acc: 400.00000\n",
            "epoch: [30/50] train_loss: 0.00035 train_acc: 500.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [30/50] train_loss: 0.00060 train_acc: 700.00000\n",
            "epoch: [30/50] train_loss: 0.00002 train_acc: 800.00000\n",
            "epoch: [30/50] train_loss: 0.00055 train_acc: 900.00000\n",
            "epoch: [30/50] train_loss: 0.00023 train_acc: 1000.00000\n",
            "epoch: [30/50] train_loss: 0.00004 train_acc: 1100.00000\n",
            "epoch: [30/50] train_loss: 0.00002 train_acc: 1200.00000\n",
            "epoch: [30/50] train_loss: 0.00005 train_acc: 1300.00000\n",
            "epoch: [30/50] train_loss: 0.00002 train_acc: 1400.00000\n",
            "epoch: [31/50] train_loss: 0.04656 train_acc: 98.75000\n",
            "epoch: [31/50] train_loss: 0.04419 train_acc: 197.50000\n",
            "epoch: [31/50] train_loss: 0.11959 train_acc: 295.00000\n",
            "epoch: [31/50] train_loss: 0.00729 train_acc: 395.00000\n",
            "epoch: [31/50] train_loss: 0.01105 train_acc: 495.00000\n",
            "epoch: [31/50] train_loss: 0.04252 train_acc: 593.75000\n",
            "epoch: [31/50] train_loss: 0.00170 train_acc: 693.75000\n",
            "epoch: [31/50] train_loss: 0.01138 train_acc: 793.75000\n",
            "epoch: [31/50] train_loss: 0.01506 train_acc: 892.50000\n",
            "epoch: [31/50] train_loss: 0.00483 train_acc: 992.50000\n",
            "epoch: [31/50] train_loss: 0.00019 train_acc: 1092.50000\n",
            "epoch: [31/50] train_loss: 0.00007 train_acc: 1192.50000\n",
            "epoch: [31/50] train_loss: 0.00030 train_acc: 1292.50000\n",
            "epoch: [31/50] train_loss: 0.00035 train_acc: 1392.50000\n",
            "epoch: [32/50] train_loss: 0.01180 train_acc: 98.75000\n",
            "epoch: [32/50] train_loss: 0.00452 train_acc: 198.75000\n",
            "epoch: [32/50] train_loss: 0.00139 train_acc: 298.75000\n",
            "epoch: [32/50] train_loss: 0.00160 train_acc: 398.75000\n",
            "epoch: [32/50] train_loss: 0.01035 train_acc: 497.50000\n",
            "epoch: [32/50] train_loss: 0.00658 train_acc: 597.50000\n",
            "epoch: [32/50] train_loss: 0.00021 train_acc: 697.50000\n",
            "epoch: [32/50] train_loss: 0.00009 train_acc: 797.50000\n",
            "epoch: [32/50] train_loss: 0.00127 train_acc: 897.50000\n",
            "epoch: [32/50] train_loss: 0.00029 train_acc: 997.50000\n",
            "epoch: [32/50] train_loss: 0.00011 train_acc: 1097.50000\n",
            "epoch: [32/50] train_loss: 0.01121 train_acc: 1196.25000\n",
            "epoch: [32/50] train_loss: 0.01073 train_acc: 1296.25000\n",
            "epoch: [32/50] train_loss: 0.00103 train_acc: 1396.25000\n",
            "epoch: [33/50] train_loss: 0.00429 train_acc: 100.00000\n",
            "epoch: [33/50] train_loss: 0.00610 train_acc: 200.00000\n",
            "epoch: [33/50] train_loss: 0.00005 train_acc: 300.00000\n",
            "epoch: [33/50] train_loss: 0.00210 train_acc: 400.00000\n",
            "epoch: [33/50] train_loss: 0.00076 train_acc: 500.00000\n",
            "epoch: [33/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [33/50] train_loss: 0.00296 train_acc: 700.00000\n",
            "epoch: [33/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [33/50] train_loss: 0.00117 train_acc: 900.00000\n",
            "epoch: [33/50] train_loss: 0.00014 train_acc: 1000.00000\n",
            "epoch: [33/50] train_loss: 0.00005 train_acc: 1100.00000\n",
            "epoch: [33/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [33/50] train_loss: 0.00211 train_acc: 1300.00000\n",
            "epoch: [33/50] train_loss: 0.00004 train_acc: 1400.00000\n",
            "epoch: [34/50] train_loss: 0.00136 train_acc: 100.00000\n",
            "epoch: [34/50] train_loss: 0.00261 train_acc: 200.00000\n",
            "epoch: [34/50] train_loss: 0.00546 train_acc: 300.00000\n",
            "epoch: [34/50] train_loss: 0.13550 train_acc: 393.75000\n",
            "epoch: [34/50] train_loss: 0.00640 train_acc: 493.75000\n",
            "epoch: [34/50] train_loss: 0.00713 train_acc: 593.75000\n",
            "epoch: [34/50] train_loss: 0.00091 train_acc: 693.75000\n",
            "epoch: [34/50] train_loss: 0.00020 train_acc: 793.75000\n",
            "epoch: [34/50] train_loss: 0.00030 train_acc: 893.75000\n",
            "epoch: [34/50] train_loss: 0.00126 train_acc: 993.75000\n",
            "epoch: [34/50] train_loss: 0.00011 train_acc: 1093.75000\n",
            "epoch: [34/50] train_loss: 0.00004 train_acc: 1193.75000\n",
            "epoch: [34/50] train_loss: 0.00064 train_acc: 1293.75000\n",
            "epoch: [34/50] train_loss: 0.00019 train_acc: 1393.75000\n",
            "epoch: [35/50] train_loss: 0.02531 train_acc: 97.50000\n",
            "epoch: [35/50] train_loss: 0.00400 train_acc: 197.50000\n",
            "epoch: [35/50] train_loss: 0.00675 train_acc: 297.50000\n",
            "epoch: [35/50] train_loss: 0.02419 train_acc: 396.25000\n",
            "epoch: [35/50] train_loss: 0.00012 train_acc: 496.25000\n",
            "epoch: [35/50] train_loss: 0.00011 train_acc: 596.25000\n",
            "epoch: [35/50] train_loss: 0.02302 train_acc: 695.00000\n",
            "epoch: [35/50] train_loss: 0.06663 train_acc: 793.75000\n",
            "epoch: [35/50] train_loss: 0.01519 train_acc: 892.50000\n",
            "epoch: [35/50] train_loss: 0.00544 train_acc: 992.50000\n",
            "epoch: [35/50] train_loss: 0.00037 train_acc: 1092.50000\n",
            "epoch: [35/50] train_loss: 0.00027 train_acc: 1192.50000\n",
            "epoch: [35/50] train_loss: 0.00109 train_acc: 1292.50000\n",
            "epoch: [35/50] train_loss: 0.00038 train_acc: 1392.50000\n",
            "epoch: [36/50] train_loss: 0.00140 train_acc: 100.00000\n",
            "epoch: [36/50] train_loss: 0.10798 train_acc: 197.50000\n",
            "epoch: [36/50] train_loss: 0.06303 train_acc: 293.75000\n",
            "epoch: [36/50] train_loss: 0.08345 train_acc: 390.00000\n",
            "epoch: [36/50] train_loss: 0.01420 train_acc: 490.00000\n",
            "epoch: [36/50] train_loss: 0.00061 train_acc: 590.00000\n",
            "epoch: [36/50] train_loss: 0.05044 train_acc: 688.75000\n",
            "epoch: [36/50] train_loss: 0.00895 train_acc: 788.75000\n",
            "epoch: [36/50] train_loss: 0.00371 train_acc: 888.75000\n",
            "epoch: [36/50] train_loss: 0.00283 train_acc: 988.75000\n",
            "epoch: [36/50] train_loss: 0.00064 train_acc: 1088.75000\n",
            "epoch: [36/50] train_loss: 0.00015 train_acc: 1188.75000\n",
            "epoch: [36/50] train_loss: 0.00189 train_acc: 1288.75000\n",
            "epoch: [36/50] train_loss: 0.00721 train_acc: 1388.75000\n",
            "epoch: [37/50] train_loss: 0.02519 train_acc: 98.75000\n",
            "epoch: [37/50] train_loss: 0.00135 train_acc: 198.75000\n",
            "epoch: [37/50] train_loss: 0.01957 train_acc: 297.50000\n",
            "epoch: [37/50] train_loss: 0.00375 train_acc: 397.50000\n",
            "epoch: [37/50] train_loss: 0.00152 train_acc: 497.50000\n",
            "epoch: [37/50] train_loss: 0.00006 train_acc: 597.50000\n",
            "epoch: [37/50] train_loss: 0.00057 train_acc: 697.50000\n",
            "epoch: [37/50] train_loss: 0.00013 train_acc: 797.50000\n",
            "epoch: [37/50] train_loss: 0.00112 train_acc: 897.50000\n",
            "epoch: [37/50] train_loss: 0.00013 train_acc: 997.50000\n",
            "epoch: [37/50] train_loss: 0.00008 train_acc: 1097.50000\n",
            "epoch: [37/50] train_loss: 0.00004 train_acc: 1197.50000\n",
            "epoch: [37/50] train_loss: 0.00024 train_acc: 1297.50000\n",
            "epoch: [37/50] train_loss: 0.00041 train_acc: 1397.50000\n",
            "epoch: [38/50] train_loss: 0.00185 train_acc: 100.00000\n",
            "epoch: [38/50] train_loss: 0.00025 train_acc: 200.00000\n",
            "epoch: [38/50] train_loss: 0.00011 train_acc: 300.00000\n",
            "epoch: [38/50] train_loss: 0.00049 train_acc: 400.00000\n",
            "epoch: [38/50] train_loss: 0.00036 train_acc: 500.00000\n",
            "epoch: [38/50] train_loss: 0.00003 train_acc: 600.00000\n",
            "epoch: [38/50] train_loss: 0.00032 train_acc: 700.00000\n",
            "epoch: [38/50] train_loss: 0.00007 train_acc: 800.00000\n",
            "epoch: [38/50] train_loss: 0.00041 train_acc: 900.00000\n",
            "epoch: [38/50] train_loss: 0.00009 train_acc: 1000.00000\n",
            "epoch: [38/50] train_loss: 0.00005 train_acc: 1100.00000\n",
            "epoch: [38/50] train_loss: 0.00003 train_acc: 1200.00000\n",
            "epoch: [38/50] train_loss: 0.00014 train_acc: 1300.00000\n",
            "epoch: [38/50] train_loss: 0.00018 train_acc: 1400.00000\n",
            "epoch: [39/50] train_loss: 0.00070 train_acc: 100.00000\n",
            "epoch: [39/50] train_loss: 0.00012 train_acc: 200.00000\n",
            "epoch: [39/50] train_loss: 0.00005 train_acc: 300.00000\n",
            "epoch: [39/50] train_loss: 0.00026 train_acc: 400.00000\n",
            "epoch: [39/50] train_loss: 0.00024 train_acc: 500.00000\n",
            "epoch: [39/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [39/50] train_loss: 0.00016 train_acc: 700.00000\n",
            "epoch: [39/50] train_loss: 0.00004 train_acc: 800.00000\n",
            "epoch: [39/50] train_loss: 0.00021 train_acc: 900.00000\n",
            "epoch: [39/50] train_loss: 0.00008 train_acc: 1000.00000\n",
            "epoch: [39/50] train_loss: 0.00004 train_acc: 1100.00000\n",
            "epoch: [39/50] train_loss: 0.00002 train_acc: 1200.00000\n",
            "epoch: [39/50] train_loss: 0.00009 train_acc: 1300.00000\n",
            "epoch: [39/50] train_loss: 0.00013 train_acc: 1400.00000\n",
            "epoch: [40/50] train_loss: 0.00028 train_acc: 100.00000\n",
            "epoch: [40/50] train_loss: 0.00006 train_acc: 200.00000\n",
            "epoch: [40/50] train_loss: 0.00004 train_acc: 300.00000\n",
            "epoch: [40/50] train_loss: 0.00018 train_acc: 400.00000\n",
            "epoch: [40/50] train_loss: 0.00013 train_acc: 500.00000\n",
            "epoch: [40/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [40/50] train_loss: 0.00009 train_acc: 700.00000\n",
            "epoch: [40/50] train_loss: 0.00002 train_acc: 800.00000\n",
            "epoch: [40/50] train_loss: 0.00011 train_acc: 900.00000\n",
            "epoch: [40/50] train_loss: 0.00009 train_acc: 1000.00000\n",
            "epoch: [40/50] train_loss: 0.00003 train_acc: 1100.00000\n",
            "epoch: [40/50] train_loss: 0.00002 train_acc: 1200.00000\n",
            "epoch: [40/50] train_loss: 0.00006 train_acc: 1300.00000\n",
            "epoch: [40/50] train_loss: 0.00008 train_acc: 1400.00000\n",
            "epoch: [41/50] train_loss: 0.00018 train_acc: 100.00000\n",
            "epoch: [41/50] train_loss: 0.00006 train_acc: 200.00000\n",
            "epoch: [41/50] train_loss: 0.00003 train_acc: 300.00000\n",
            "epoch: [41/50] train_loss: 0.00011 train_acc: 400.00000\n",
            "epoch: [41/50] train_loss: 0.00009 train_acc: 500.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [41/50] train_loss: 0.00006 train_acc: 700.00000\n",
            "epoch: [41/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [41/50] train_loss: 0.00008 train_acc: 900.00000\n",
            "epoch: [41/50] train_loss: 0.00007 train_acc: 1000.00000\n",
            "epoch: [41/50] train_loss: 0.00003 train_acc: 1100.00000\n",
            "epoch: [41/50] train_loss: 0.00002 train_acc: 1200.00000\n",
            "epoch: [41/50] train_loss: 0.00003 train_acc: 1300.00000\n",
            "epoch: [41/50] train_loss: 0.00006 train_acc: 1400.00000\n",
            "epoch: [42/50] train_loss: 0.00012 train_acc: 100.00000\n",
            "epoch: [42/50] train_loss: 0.00006 train_acc: 200.00000\n",
            "epoch: [42/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [42/50] train_loss: 0.00006 train_acc: 400.00000\n",
            "epoch: [42/50] train_loss: 0.00006 train_acc: 500.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [42/50] train_loss: 0.00005 train_acc: 700.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [42/50] train_loss: 0.00005 train_acc: 900.00000\n",
            "epoch: [42/50] train_loss: 0.00005 train_acc: 1000.00000\n",
            "epoch: [42/50] train_loss: 0.00002 train_acc: 1100.00000\n",
            "epoch: [42/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [42/50] train_loss: 0.00002 train_acc: 1300.00000\n",
            "epoch: [42/50] train_loss: 0.00004 train_acc: 1400.00000\n",
            "epoch: [43/50] train_loss: 0.00008 train_acc: 100.00000\n",
            "epoch: [43/50] train_loss: 0.00006 train_acc: 200.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [43/50] train_loss: 0.00004 train_acc: 400.00000\n",
            "epoch: [43/50] train_loss: 0.00003 train_acc: 500.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [43/50] train_loss: 0.00004 train_acc: 700.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [43/50] train_loss: 0.00005 train_acc: 900.00000\n",
            "epoch: [43/50] train_loss: 0.00005 train_acc: 1000.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [43/50] train_loss: 0.00002 train_acc: 1400.00000\n",
            "epoch: [44/50] train_loss: 0.00005 train_acc: 100.00000\n",
            "epoch: [44/50] train_loss: 0.00003 train_acc: 200.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [44/50] train_loss: 0.00002 train_acc: 400.00000\n",
            "epoch: [44/50] train_loss: 0.00002 train_acc: 500.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [44/50] train_loss: 0.00003 train_acc: 700.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [44/50] train_loss: 0.00003 train_acc: 900.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [45/50] train_loss: 0.00003 train_acc: 100.00000\n",
            "epoch: [45/50] train_loss: 0.00003 train_acc: 200.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [45/50] train_loss: 0.00002 train_acc: 400.00000\n",
            "epoch: [45/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [45/50] train_loss: 0.00002 train_acc: 700.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [45/50] train_loss: 0.00002 train_acc: 900.00000\n",
            "epoch: [45/50] train_loss: 0.00006 train_acc: 1000.00000\n",
            "epoch: [45/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [45/50] train_loss: 0.00017 train_acc: 1300.00000\n",
            "epoch: [45/50] train_loss: 0.00003 train_acc: 1400.00000\n",
            "epoch: [46/50] train_loss: 0.13889 train_acc: 98.75000\n",
            "epoch: [46/50] train_loss: 0.07825 train_acc: 197.50000\n",
            "epoch: [46/50] train_loss: 0.01971 train_acc: 296.25000\n",
            "epoch: [46/50] train_loss: 0.00937 train_acc: 396.25000\n",
            "epoch: [46/50] train_loss: 0.00570 train_acc: 496.25000\n",
            "epoch: [46/50] train_loss: 0.05248 train_acc: 595.00000\n",
            "epoch: [46/50] train_loss: 0.04320 train_acc: 693.75000\n",
            "epoch: [46/50] train_loss: 0.12160 train_acc: 792.50000\n",
            "epoch: [46/50] train_loss: 0.00287 train_acc: 892.50000\n",
            "epoch: [46/50] train_loss: 0.02705 train_acc: 991.25000\n",
            "epoch: [46/50] train_loss: 0.00085 train_acc: 1091.25000\n",
            "epoch: [46/50] train_loss: 0.00041 train_acc: 1191.25000\n",
            "epoch: [46/50] train_loss: 0.00066 train_acc: 1291.25000\n",
            "epoch: [46/50] train_loss: 0.00205 train_acc: 1391.25000\n",
            "epoch: [47/50] train_loss: 0.00377 train_acc: 100.00000\n",
            "epoch: [47/50] train_loss: 0.00082 train_acc: 200.00000\n",
            "epoch: [47/50] train_loss: 0.00029 train_acc: 300.00000\n",
            "epoch: [47/50] train_loss: 0.00034 train_acc: 400.00000\n",
            "epoch: [47/50] train_loss: 0.00048 train_acc: 500.00000\n",
            "epoch: [47/50] train_loss: 0.00002 train_acc: 600.00000\n",
            "epoch: [47/50] train_loss: 0.00043 train_acc: 700.00000\n",
            "epoch: [47/50] train_loss: 0.00010 train_acc: 800.00000\n",
            "epoch: [47/50] train_loss: 0.00030 train_acc: 900.00000\n",
            "epoch: [47/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [47/50] train_loss: 0.00002 train_acc: 1100.00000\n",
            "epoch: [47/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [47/50] train_loss: 0.00008 train_acc: 1300.00000\n",
            "epoch: [47/50] train_loss: 0.00011 train_acc: 1400.00000\n",
            "epoch: [48/50] train_loss: 0.00166 train_acc: 100.00000\n",
            "epoch: [48/50] train_loss: 0.00051 train_acc: 200.00000\n",
            "epoch: [48/50] train_loss: 0.00002 train_acc: 300.00000\n",
            "epoch: [48/50] train_loss: 0.00016 train_acc: 400.00000\n",
            "epoch: [48/50] train_loss: 0.00048 train_acc: 500.00000\n",
            "epoch: [48/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [48/50] train_loss: 0.00031 train_acc: 700.00000\n",
            "epoch: [48/50] train_loss: 0.00007 train_acc: 800.00000\n",
            "epoch: [48/50] train_loss: 0.00032 train_acc: 900.00000\n",
            "epoch: [48/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [48/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [48/50] train_loss: 0.00006 train_acc: 1300.00000\n",
            "epoch: [48/50] train_loss: 0.00008 train_acc: 1400.00000\n",
            "epoch: [49/50] train_loss: 0.00006 train_acc: 100.00000\n",
            "epoch: [49/50] train_loss: 0.00003 train_acc: 200.00000\n",
            "epoch: [49/50] train_loss: 0.00012 train_acc: 300.00000\n",
            "epoch: [49/50] train_loss: 0.00009 train_acc: 400.00000\n",
            "epoch: [49/50] train_loss: 0.00013 train_acc: 500.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [49/50] train_loss: 0.00013 train_acc: 700.00000\n",
            "epoch: [49/50] train_loss: 0.00002 train_acc: 800.00000\n",
            "epoch: [49/50] train_loss: 0.00004 train_acc: 900.00000\n",
            "epoch: [49/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [49/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [49/50] train_loss: 0.00003 train_acc: 1300.00000\n",
            "epoch: [49/50] train_loss: 0.00004 train_acc: 1400.00000\n",
            "epoch: [50/50] train_loss: 0.00006 train_acc: 100.00000\n",
            "epoch: [50/50] train_loss: 0.00002 train_acc: 200.00000\n",
            "epoch: [50/50] train_loss: 0.00006 train_acc: 300.00000\n",
            "epoch: [50/50] train_loss: 0.00007 train_acc: 400.00000\n",
            "epoch: [50/50] train_loss: 0.00008 train_acc: 500.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [50/50] train_loss: 0.00008 train_acc: 700.00000\n",
            "epoch: [50/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [50/50] train_loss: 0.00003 train_acc: 900.00000\n",
            "epoch: [50/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [50/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [50/50] train_loss: 0.00002 train_acc: 1300.00000\n",
            "epoch: [50/50] train_loss: 0.00003 train_acc: 1400.00000\n",
            "learning finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **test**"
      ],
      "metadata": {
        "id": "HFx3geHA-NxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    total_acc = 0.0\n",
        "    acc = 0.0\n",
        "    data = x_test.to('cuda')\n",
        "    labels = y_test.to('cuda')\n",
        "\n",
        "    for i,data in enumerate(x_test, 0):\n",
        "        data = data.to('cuda')\n",
        "        labels = y_test.to('cuda')\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        acc = accuracy(outputs, k)\n",
        "        total_acc += acc\n",
        "\n",
        "        count = i\n",
        "\n",
        "    print('avarage acc: %.5f' % (total_acc/count),'%')\n",
        "\n",
        "print('test finish!')"
      ],
      "metadata": {
        "id": "pEQnYvCZKTLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31069c26-af4c-4512-8fd7-79d0d03fe33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avarage acc: 97.92388 %\n",
            "test finish!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(pred):\n",
        "  pred = pred\n",
        "  outputs = model(pred)\n",
        "  pred_tag = torch.round(torch.sigmoid(outputs))\n",
        "  #pred_tag = torch.sigmoid(outputs)\n",
        "  return pred_tag"
      ],
      "metadata": {
        "id": "ONF5FP-Ntl89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predicts(pred):\n",
        "  pred = pred\n",
        "  outputs = model(pred)\n",
        "  pred_tag = torch.sigmoid(outputs)\n",
        "  return pred_tag"
      ],
      "metadata": {
        "id": "cpg9VSSVuQG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **test해보기**"
      ],
      "metadata": {
        "id": "M2Y6lvdYuAwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = PIL.Image.open('/content/눈사진.jpg')\n",
        "img =image.resize((64,64))\n",
        "plt.imshow(img)\n",
        "re_img = tf(img) # 해주면 image의 shape는 (3,64,64) 이된다\n",
        "re_img = re_img.to('cuda')\n",
        "pred_tag = predict(re_img)\n",
        "print(\"눈사진: \", pred_tag)\n",
        "\n",
        "prediction = predicts(re_img)\n",
        " \n",
        "if prediction < 0.5: # 눈이 감으면\n",
        "   text = \"Closed ({:.2f}%)\".format((1 - prediction[0][0])*100)\n",
        "   print(text)\n",
        "\n",
        "else: #눈을 뜨면\n",
        "   text = \"Open ({:.2f}%)\".format(prediction[0][0]*100)\n",
        "   print(text)"
      ],
      "metadata": {
        "id": "J_2cXFaW-lp7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "e4c308d2-9045-4048-ed1c-7d97f5fd26a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c1d2e18a8ec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/눈사진.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mre_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 해주면 image의 shape는 (3,64,64) 이된다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mre_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/눈사진.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image2 = PIL.Image.open('/content/눈감음.jpg')\n",
        "img2 =image2.resize((64,64))\n",
        "plt.imshow(img2)\n",
        "re_img2 = tf(img2) # 해주면 image의 shape는 (3,64,64) 이된다\n",
        "re_img2 = re_img2.to('cuda')\n",
        "pred_tag2 = predict(re_img2)\n",
        "print(\"눈사진: \", pred_tag2)\n",
        "\n",
        "prediction = predicts(re_img2)\n",
        " \n",
        "if prediction < 0.5: # 눈이 감으면\n",
        "   text = \"Closed ({:.2f}%)\".format((1 - prediction[0][0])*100)\n",
        "   print(text)\n",
        "\n",
        "else: #눈을 뜨면\n",
        "   text = \"Open ({:.2f}%)\".format(prediction[0][0]*100)\n",
        "   print(text)"
      ],
      "metadata": {
        "id": "BAIHvUA2tviH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 수정해보기 1 : layer를 늘려보자"
      ],
      "metadata": {
        "id": "c-ggDqtWzXYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1) #  추가시켜줌\n",
        "        self.fc1 = nn.Linear(2048, 512) \n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.reshape(-1, 2048)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model.to('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "2MnwY6m4uMM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i,data in enumerate(x_train, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to('cuda')\n",
        "        labels = y_train.to('cuda')\n",
        "\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        #print(\"intpus_1 shape: \",input_1.shape)\n",
        "        #print(\"outputs shape: \",outputs.shape)\n",
        "        #print(\"labels shape\",labels.shape)\n",
        "         #labels = labels.view(len(labels),-1)\n",
        "        loss = criterion(outputs, k)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += accuracy(outputs, k)\n",
        "\n",
        "        if i % 80 == 79:\n",
        "            print('epoch: [%d/%d] train_loss: %.5f train_acc: %.5f' % (\n",
        "                epoch + 1, epochs, running_loss / 80, running_acc / 80))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"learning finish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6TVpp20zjne",
        "outputId": "96b56dba-e64d-4b7b-99e6-f4f163d17052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/50] train_loss: 0.69531 train_acc: 47.50000\n",
            "epoch: [1/50] train_loss: 0.69258 train_acc: 96.25000\n",
            "epoch: [1/50] train_loss: 0.64048 train_acc: 165.00000\n",
            "epoch: [1/50] train_loss: 0.49626 train_acc: 245.00000\n",
            "epoch: [1/50] train_loss: 0.27600 train_acc: 332.50000\n",
            "epoch: [1/50] train_loss: 0.27318 train_acc: 423.75000\n",
            "epoch: [1/50] train_loss: 0.18283 train_acc: 517.50000\n",
            "epoch: [1/50] train_loss: 0.22324 train_acc: 607.50000\n",
            "epoch: [1/50] train_loss: 0.14839 train_acc: 700.00000\n",
            "epoch: [1/50] train_loss: 0.21731 train_acc: 792.50000\n",
            "epoch: [1/50] train_loss: 0.11580 train_acc: 890.00000\n",
            "epoch: [1/50] train_loss: 0.07603 train_acc: 988.75000\n",
            "epoch: [1/50] train_loss: 0.11573 train_acc: 1083.75000\n",
            "epoch: [1/50] train_loss: 0.20375 train_acc: 1176.25000\n",
            "epoch: [2/50] train_loss: 0.17389 train_acc: 95.00000\n",
            "epoch: [2/50] train_loss: 0.31015 train_acc: 183.75000\n",
            "epoch: [2/50] train_loss: 0.14034 train_acc: 280.00000\n",
            "epoch: [2/50] train_loss: 0.16060 train_acc: 373.75000\n",
            "epoch: [2/50] train_loss: 0.05803 train_acc: 471.25000\n",
            "epoch: [2/50] train_loss: 0.15253 train_acc: 566.25000\n",
            "epoch: [2/50] train_loss: 0.08292 train_acc: 665.00000\n",
            "epoch: [2/50] train_loss: 0.15006 train_acc: 760.00000\n",
            "epoch: [2/50] train_loss: 0.07245 train_acc: 858.75000\n",
            "epoch: [2/50] train_loss: 0.13099 train_acc: 952.50000\n",
            "epoch: [2/50] train_loss: 0.08480 train_acc: 1050.00000\n",
            "epoch: [2/50] train_loss: 0.03334 train_acc: 1150.00000\n",
            "epoch: [2/50] train_loss: 0.06640 train_acc: 1248.75000\n",
            "epoch: [2/50] train_loss: 0.13007 train_acc: 1343.75000\n",
            "epoch: [3/50] train_loss: 0.16456 train_acc: 96.25000\n",
            "epoch: [3/50] train_loss: 0.24787 train_acc: 188.75000\n",
            "epoch: [3/50] train_loss: 0.09819 train_acc: 286.25000\n",
            "epoch: [3/50] train_loss: 0.08779 train_acc: 383.75000\n",
            "epoch: [3/50] train_loss: 0.02786 train_acc: 483.75000\n",
            "epoch: [3/50] train_loss: 0.08426 train_acc: 578.75000\n",
            "epoch: [3/50] train_loss: 0.05002 train_acc: 677.50000\n",
            "epoch: [3/50] train_loss: 0.10242 train_acc: 773.75000\n",
            "epoch: [3/50] train_loss: 0.03865 train_acc: 872.50000\n",
            "epoch: [3/50] train_loss: 0.08284 train_acc: 968.75000\n",
            "epoch: [3/50] train_loss: 0.06440 train_acc: 1067.50000\n",
            "epoch: [3/50] train_loss: 0.02466 train_acc: 1167.50000\n",
            "epoch: [3/50] train_loss: 0.04668 train_acc: 1266.25000\n",
            "epoch: [3/50] train_loss: 0.03208 train_acc: 1366.25000\n",
            "epoch: [4/50] train_loss: 0.17200 train_acc: 96.25000\n",
            "epoch: [4/50] train_loss: 0.19297 train_acc: 191.25000\n",
            "epoch: [4/50] train_loss: 0.10069 train_acc: 288.75000\n",
            "epoch: [4/50] train_loss: 0.06249 train_acc: 385.00000\n",
            "epoch: [4/50] train_loss: 0.01990 train_acc: 485.00000\n",
            "epoch: [4/50] train_loss: 0.09754 train_acc: 582.50000\n",
            "epoch: [4/50] train_loss: 0.03645 train_acc: 681.25000\n",
            "epoch: [4/50] train_loss: 0.05230 train_acc: 780.00000\n",
            "epoch: [4/50] train_loss: 0.03016 train_acc: 880.00000\n",
            "epoch: [4/50] train_loss: 0.05660 train_acc: 978.75000\n",
            "epoch: [4/50] train_loss: 0.04581 train_acc: 1077.50000\n",
            "epoch: [4/50] train_loss: 0.03747 train_acc: 1175.00000\n",
            "epoch: [4/50] train_loss: 0.03814 train_acc: 1273.75000\n",
            "epoch: [4/50] train_loss: 0.01698 train_acc: 1373.75000\n",
            "epoch: [5/50] train_loss: 0.13202 train_acc: 96.25000\n",
            "epoch: [5/50] train_loss: 0.15073 train_acc: 191.25000\n",
            "epoch: [5/50] train_loss: 0.05761 train_acc: 290.00000\n",
            "epoch: [5/50] train_loss: 0.05231 train_acc: 387.50000\n",
            "epoch: [5/50] train_loss: 0.01190 train_acc: 487.50000\n",
            "epoch: [5/50] train_loss: 0.08313 train_acc: 585.00000\n",
            "epoch: [5/50] train_loss: 0.02949 train_acc: 685.00000\n",
            "epoch: [5/50] train_loss: 0.02375 train_acc: 785.00000\n",
            "epoch: [5/50] train_loss: 0.02621 train_acc: 885.00000\n",
            "epoch: [5/50] train_loss: 0.03779 train_acc: 983.75000\n",
            "epoch: [5/50] train_loss: 0.03005 train_acc: 1082.50000\n",
            "epoch: [5/50] train_loss: 0.01494 train_acc: 1182.50000\n",
            "epoch: [5/50] train_loss: 0.00731 train_acc: 1282.50000\n",
            "epoch: [5/50] train_loss: 0.00604 train_acc: 1382.50000\n",
            "epoch: [6/50] train_loss: 0.12782 train_acc: 96.25000\n",
            "epoch: [6/50] train_loss: 0.15124 train_acc: 192.50000\n",
            "epoch: [6/50] train_loss: 0.05301 train_acc: 291.25000\n",
            "epoch: [6/50] train_loss: 0.03013 train_acc: 390.00000\n",
            "epoch: [6/50] train_loss: 0.00989 train_acc: 490.00000\n",
            "epoch: [6/50] train_loss: 0.04858 train_acc: 587.50000\n",
            "epoch: [6/50] train_loss: 0.03169 train_acc: 686.25000\n",
            "epoch: [6/50] train_loss: 0.01742 train_acc: 786.25000\n",
            "epoch: [6/50] train_loss: 0.01489 train_acc: 886.25000\n",
            "epoch: [6/50] train_loss: 0.03649 train_acc: 985.00000\n",
            "epoch: [6/50] train_loss: 0.03110 train_acc: 1083.75000\n",
            "epoch: [6/50] train_loss: 0.00356 train_acc: 1183.75000\n",
            "epoch: [6/50] train_loss: 0.00489 train_acc: 1283.75000\n",
            "epoch: [6/50] train_loss: 0.00370 train_acc: 1383.75000\n",
            "epoch: [7/50] train_loss: 0.07655 train_acc: 97.50000\n",
            "epoch: [7/50] train_loss: 0.11391 train_acc: 193.75000\n",
            "epoch: [7/50] train_loss: 0.04680 train_acc: 292.50000\n",
            "epoch: [7/50] train_loss: 0.02708 train_acc: 392.50000\n",
            "epoch: [7/50] train_loss: 0.00618 train_acc: 492.50000\n",
            "epoch: [7/50] train_loss: 0.03592 train_acc: 590.00000\n",
            "epoch: [7/50] train_loss: 0.03788 train_acc: 687.50000\n",
            "epoch: [7/50] train_loss: 0.01805 train_acc: 786.25000\n",
            "epoch: [7/50] train_loss: 0.01871 train_acc: 885.00000\n",
            "epoch: [7/50] train_loss: 0.02012 train_acc: 985.00000\n",
            "epoch: [7/50] train_loss: 0.00887 train_acc: 1085.00000\n",
            "epoch: [7/50] train_loss: 0.00465 train_acc: 1185.00000\n",
            "epoch: [7/50] train_loss: 0.00185 train_acc: 1285.00000\n",
            "epoch: [7/50] train_loss: 0.00235 train_acc: 1385.00000\n",
            "epoch: [8/50] train_loss: 0.04725 train_acc: 98.75000\n",
            "epoch: [8/50] train_loss: 0.09236 train_acc: 195.00000\n",
            "epoch: [8/50] train_loss: 0.04061 train_acc: 293.75000\n",
            "epoch: [8/50] train_loss: 0.02184 train_acc: 393.75000\n",
            "epoch: [8/50] train_loss: 0.00647 train_acc: 493.75000\n",
            "epoch: [8/50] train_loss: 0.03164 train_acc: 592.50000\n",
            "epoch: [8/50] train_loss: 0.02494 train_acc: 692.50000\n",
            "epoch: [8/50] train_loss: 0.01875 train_acc: 791.25000\n",
            "epoch: [8/50] train_loss: 0.00708 train_acc: 891.25000\n",
            "epoch: [8/50] train_loss: 0.01986 train_acc: 990.00000\n",
            "epoch: [8/50] train_loss: 0.02271 train_acc: 1088.75000\n",
            "epoch: [8/50] train_loss: 0.00251 train_acc: 1188.75000\n",
            "epoch: [8/50] train_loss: 0.00301 train_acc: 1288.75000\n",
            "epoch: [8/50] train_loss: 0.00313 train_acc: 1388.75000\n",
            "epoch: [9/50] train_loss: 0.02579 train_acc: 98.75000\n",
            "epoch: [9/50] train_loss: 0.04924 train_acc: 197.50000\n",
            "epoch: [9/50] train_loss: 0.03396 train_acc: 296.25000\n",
            "epoch: [9/50] train_loss: 0.01419 train_acc: 396.25000\n",
            "epoch: [9/50] train_loss: 0.00296 train_acc: 496.25000\n",
            "epoch: [9/50] train_loss: 0.01754 train_acc: 595.00000\n",
            "epoch: [9/50] train_loss: 0.01387 train_acc: 695.00000\n",
            "epoch: [9/50] train_loss: 0.01643 train_acc: 795.00000\n",
            "epoch: [9/50] train_loss: 0.01079 train_acc: 895.00000\n",
            "epoch: [9/50] train_loss: 0.00548 train_acc: 995.00000\n",
            "epoch: [9/50] train_loss: 0.00307 train_acc: 1095.00000\n",
            "epoch: [9/50] train_loss: 0.00029 train_acc: 1195.00000\n",
            "epoch: [9/50] train_loss: 0.00094 train_acc: 1295.00000\n",
            "epoch: [9/50] train_loss: 0.00080 train_acc: 1395.00000\n",
            "epoch: [10/50] train_loss: 0.01317 train_acc: 98.75000\n",
            "epoch: [10/50] train_loss: 0.03170 train_acc: 196.25000\n",
            "epoch: [10/50] train_loss: 0.01368 train_acc: 296.25000\n",
            "epoch: [10/50] train_loss: 0.01437 train_acc: 395.00000\n",
            "epoch: [10/50] train_loss: 0.01931 train_acc: 493.75000\n",
            "epoch: [10/50] train_loss: 0.06884 train_acc: 592.50000\n",
            "epoch: [10/50] train_loss: 0.00271 train_acc: 692.50000\n",
            "epoch: [10/50] train_loss: 0.00132 train_acc: 792.50000\n",
            "epoch: [10/50] train_loss: 0.00522 train_acc: 892.50000\n",
            "epoch: [10/50] train_loss: 0.02160 train_acc: 991.25000\n",
            "epoch: [10/50] train_loss: 0.01371 train_acc: 1091.25000\n",
            "epoch: [10/50] train_loss: 0.00076 train_acc: 1191.25000\n",
            "epoch: [10/50] train_loss: 0.00261 train_acc: 1291.25000\n",
            "epoch: [10/50] train_loss: 0.00150 train_acc: 1391.25000\n",
            "epoch: [11/50] train_loss: 0.02621 train_acc: 97.50000\n",
            "epoch: [11/50] train_loss: 0.01240 train_acc: 197.50000\n",
            "epoch: [11/50] train_loss: 0.06375 train_acc: 293.75000\n",
            "epoch: [11/50] train_loss: 0.02079 train_acc: 392.50000\n",
            "epoch: [11/50] train_loss: 0.00157 train_acc: 492.50000\n",
            "epoch: [11/50] train_loss: 0.11448 train_acc: 590.00000\n",
            "epoch: [11/50] train_loss: 0.01988 train_acc: 688.75000\n",
            "epoch: [11/50] train_loss: 0.00248 train_acc: 788.75000\n",
            "epoch: [11/50] train_loss: 0.01912 train_acc: 887.50000\n",
            "epoch: [11/50] train_loss: 0.09302 train_acc: 985.00000\n",
            "epoch: [11/50] train_loss: 0.00648 train_acc: 1085.00000\n",
            "epoch: [11/50] train_loss: 0.00177 train_acc: 1185.00000\n",
            "epoch: [11/50] train_loss: 0.00646 train_acc: 1285.00000\n",
            "epoch: [11/50] train_loss: 0.00071 train_acc: 1385.00000\n",
            "epoch: [12/50] train_loss: 0.00846 train_acc: 100.00000\n",
            "epoch: [12/50] train_loss: 0.02487 train_acc: 198.75000\n",
            "epoch: [12/50] train_loss: 0.03882 train_acc: 297.50000\n",
            "epoch: [12/50] train_loss: 0.04371 train_acc: 396.25000\n",
            "epoch: [12/50] train_loss: 0.00955 train_acc: 496.25000\n",
            "epoch: [12/50] train_loss: 0.01183 train_acc: 596.25000\n",
            "epoch: [12/50] train_loss: 0.00085 train_acc: 696.25000\n",
            "epoch: [12/50] train_loss: 0.00070 train_acc: 796.25000\n",
            "epoch: [12/50] train_loss: 0.00266 train_acc: 896.25000\n",
            "epoch: [12/50] train_loss: 0.00746 train_acc: 996.25000\n",
            "epoch: [12/50] train_loss: 0.00512 train_acc: 1096.25000\n",
            "epoch: [12/50] train_loss: 0.00089 train_acc: 1196.25000\n",
            "epoch: [12/50] train_loss: 0.00113 train_acc: 1296.25000\n",
            "epoch: [12/50] train_loss: 0.00159 train_acc: 1396.25000\n",
            "epoch: [13/50] train_loss: 0.00547 train_acc: 100.00000\n",
            "epoch: [13/50] train_loss: 0.00404 train_acc: 200.00000\n",
            "epoch: [13/50] train_loss: 0.00236 train_acc: 300.00000\n",
            "epoch: [13/50] train_loss: 0.00625 train_acc: 400.00000\n",
            "epoch: [13/50] train_loss: 0.00016 train_acc: 500.00000\n",
            "epoch: [13/50] train_loss: 0.00068 train_acc: 600.00000\n",
            "epoch: [13/50] train_loss: 0.00053 train_acc: 700.00000\n",
            "epoch: [13/50] train_loss: 0.00003 train_acc: 800.00000\n",
            "epoch: [13/50] train_loss: 0.00421 train_acc: 900.00000\n",
            "epoch: [13/50] train_loss: 0.00405 train_acc: 1000.00000\n",
            "epoch: [13/50] train_loss: 0.00190 train_acc: 1100.00000\n",
            "epoch: [13/50] train_loss: 0.00017 train_acc: 1200.00000\n",
            "epoch: [13/50] train_loss: 0.00041 train_acc: 1300.00000\n",
            "epoch: [13/50] train_loss: 0.00053 train_acc: 1400.00000\n",
            "epoch: [14/50] train_loss: 0.00100 train_acc: 100.00000\n",
            "epoch: [14/50] train_loss: 0.00236 train_acc: 200.00000\n",
            "epoch: [14/50] train_loss: 0.00156 train_acc: 300.00000\n",
            "epoch: [14/50] train_loss: 0.00191 train_acc: 400.00000\n",
            "epoch: [14/50] train_loss: 0.00035 train_acc: 500.00000\n",
            "epoch: [14/50] train_loss: 0.00023 train_acc: 600.00000\n",
            "epoch: [14/50] train_loss: 0.00011 train_acc: 700.00000\n",
            "epoch: [14/50] train_loss: 0.00003 train_acc: 800.00000\n",
            "epoch: [14/50] train_loss: 0.00075 train_acc: 900.00000\n",
            "epoch: [14/50] train_loss: 0.00085 train_acc: 1000.00000\n",
            "epoch: [14/50] train_loss: 0.00012 train_acc: 1100.00000\n",
            "epoch: [14/50] train_loss: 0.00016 train_acc: 1200.00000\n",
            "epoch: [14/50] train_loss: 0.00021 train_acc: 1300.00000\n",
            "epoch: [14/50] train_loss: 0.00005 train_acc: 1400.00000\n",
            "epoch: [15/50] train_loss: 0.00194 train_acc: 100.00000\n",
            "epoch: [15/50] train_loss: 0.00282 train_acc: 200.00000\n",
            "epoch: [15/50] train_loss: 0.00047 train_acc: 300.00000\n",
            "epoch: [15/50] train_loss: 0.00081 train_acc: 400.00000\n",
            "epoch: [15/50] train_loss: 0.02918 train_acc: 498.75000\n",
            "epoch: [15/50] train_loss: 0.10534 train_acc: 596.25000\n",
            "epoch: [15/50] train_loss: 0.02827 train_acc: 695.00000\n",
            "epoch: [15/50] train_loss: 0.00168 train_acc: 795.00000\n",
            "epoch: [15/50] train_loss: 0.00349 train_acc: 895.00000\n",
            "epoch: [15/50] train_loss: 0.02672 train_acc: 993.75000\n",
            "epoch: [15/50] train_loss: 0.03956 train_acc: 1092.50000\n",
            "epoch: [15/50] train_loss: 0.01654 train_acc: 1191.25000\n",
            "epoch: [15/50] train_loss: 0.01677 train_acc: 1290.00000\n",
            "epoch: [15/50] train_loss: 0.00112 train_acc: 1390.00000\n",
            "epoch: [16/50] train_loss: 0.01168 train_acc: 98.75000\n",
            "epoch: [16/50] train_loss: 0.01853 train_acc: 197.50000\n",
            "epoch: [16/50] train_loss: 0.01137 train_acc: 297.50000\n",
            "epoch: [16/50] train_loss: 0.01049 train_acc: 397.50000\n",
            "epoch: [16/50] train_loss: 0.00019 train_acc: 497.50000\n",
            "epoch: [16/50] train_loss: 0.00453 train_acc: 597.50000\n",
            "epoch: [16/50] train_loss: 0.00085 train_acc: 697.50000\n",
            "epoch: [16/50] train_loss: 0.00057 train_acc: 797.50000\n",
            "epoch: [16/50] train_loss: 0.00164 train_acc: 897.50000\n",
            "epoch: [16/50] train_loss: 0.00151 train_acc: 997.50000\n",
            "epoch: [16/50] train_loss: 0.00021 train_acc: 1097.50000\n",
            "epoch: [16/50] train_loss: 0.00017 train_acc: 1197.50000\n",
            "epoch: [16/50] train_loss: 0.00119 train_acc: 1297.50000\n",
            "epoch: [16/50] train_loss: 0.00010 train_acc: 1397.50000\n",
            "epoch: [17/50] train_loss: 0.00210 train_acc: 100.00000\n",
            "epoch: [17/50] train_loss: 0.00162 train_acc: 200.00000\n",
            "epoch: [17/50] train_loss: 0.00062 train_acc: 300.00000\n",
            "epoch: [17/50] train_loss: 0.00143 train_acc: 400.00000\n",
            "epoch: [17/50] train_loss: 0.00033 train_acc: 500.00000\n",
            "epoch: [17/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [17/50] train_loss: 0.00014 train_acc: 700.00000\n",
            "epoch: [17/50] train_loss: 0.00002 train_acc: 800.00000\n",
            "epoch: [17/50] train_loss: 0.00203 train_acc: 900.00000\n",
            "epoch: [17/50] train_loss: 0.00034 train_acc: 1000.00000\n",
            "epoch: [17/50] train_loss: 0.00006 train_acc: 1100.00000\n",
            "epoch: [17/50] train_loss: 0.00017 train_acc: 1200.00000\n",
            "epoch: [17/50] train_loss: 0.00010 train_acc: 1300.00000\n",
            "epoch: [17/50] train_loss: 0.00004 train_acc: 1400.00000\n",
            "epoch: [18/50] train_loss: 0.00061 train_acc: 100.00000\n",
            "epoch: [18/50] train_loss: 0.00074 train_acc: 200.00000\n",
            "epoch: [18/50] train_loss: 0.00064 train_acc: 300.00000\n",
            "epoch: [18/50] train_loss: 0.00047 train_acc: 400.00000\n",
            "epoch: [18/50] train_loss: 0.00059 train_acc: 500.00000\n",
            "epoch: [18/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [18/50] train_loss: 0.00006 train_acc: 700.00000\n",
            "epoch: [18/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [18/50] train_loss: 0.00034 train_acc: 900.00000\n",
            "epoch: [18/50] train_loss: 0.00008 train_acc: 1000.00000\n",
            "epoch: [18/50] train_loss: 0.00004 train_acc: 1100.00000\n",
            "epoch: [18/50] train_loss: 0.00061 train_acc: 1200.00000\n",
            "epoch: [18/50] train_loss: 0.00021 train_acc: 1300.00000\n",
            "epoch: [18/50] train_loss: 0.00004 train_acc: 1400.00000\n",
            "epoch: [19/50] train_loss: 0.00039 train_acc: 100.00000\n",
            "epoch: [19/50] train_loss: 0.00057 train_acc: 200.00000\n",
            "epoch: [19/50] train_loss: 0.00014 train_acc: 300.00000\n",
            "epoch: [19/50] train_loss: 0.00034 train_acc: 400.00000\n",
            "epoch: [19/50] train_loss: 0.00007 train_acc: 500.00000\n",
            "epoch: [19/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [19/50] train_loss: 0.00013 train_acc: 700.00000\n",
            "epoch: [19/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [19/50] train_loss: 0.00013 train_acc: 900.00000\n",
            "epoch: [19/50] train_loss: 0.00003 train_acc: 1000.00000\n",
            "epoch: [19/50] train_loss: 0.00002 train_acc: 1100.00000\n",
            "epoch: [19/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [19/50] train_loss: 0.00024 train_acc: 1300.00000\n",
            "epoch: [19/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [20/50] train_loss: 0.00028 train_acc: 100.00000\n",
            "epoch: [20/50] train_loss: 0.00028 train_acc: 200.00000\n",
            "epoch: [20/50] train_loss: 0.00010 train_acc: 300.00000\n",
            "epoch: [20/50] train_loss: 0.00013 train_acc: 400.00000\n",
            "epoch: [20/50] train_loss: 0.00008 train_acc: 500.00000\n",
            "epoch: [20/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [20/50] train_loss: 0.00004 train_acc: 700.00000\n",
            "epoch: [20/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [20/50] train_loss: 0.00010 train_acc: 900.00000\n",
            "epoch: [20/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [20/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [20/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [20/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [20/50] train_loss: 0.00002 train_acc: 1400.00000\n",
            "epoch: [21/50] train_loss: 0.00394 train_acc: 100.00000\n",
            "epoch: [21/50] train_loss: 0.14887 train_acc: 197.50000\n",
            "epoch: [21/50] train_loss: 0.06331 train_acc: 296.25000\n",
            "epoch: [21/50] train_loss: 0.02598 train_acc: 393.75000\n",
            "epoch: [21/50] train_loss: 0.00246 train_acc: 493.75000\n",
            "epoch: [21/50] train_loss: 0.02997 train_acc: 592.50000\n",
            "epoch: [21/50] train_loss: 0.00153 train_acc: 692.50000\n",
            "epoch: [21/50] train_loss: 0.09700 train_acc: 790.00000\n",
            "epoch: [21/50] train_loss: 0.04306 train_acc: 887.50000\n",
            "epoch: [21/50] train_loss: 0.00273 train_acc: 987.50000\n",
            "epoch: [21/50] train_loss: 0.00114 train_acc: 1087.50000\n",
            "epoch: [21/50] train_loss: 0.00011 train_acc: 1187.50000\n",
            "epoch: [21/50] train_loss: 0.06720 train_acc: 1285.00000\n",
            "epoch: [21/50] train_loss: 0.02810 train_acc: 1383.75000\n",
            "epoch: [22/50] train_loss: 0.00564 train_acc: 100.00000\n",
            "epoch: [22/50] train_loss: 0.00465 train_acc: 200.00000\n",
            "epoch: [22/50] train_loss: 0.07643 train_acc: 298.75000\n",
            "epoch: [22/50] train_loss: 0.01060 train_acc: 398.75000\n",
            "epoch: [22/50] train_loss: 0.00560 train_acc: 498.75000\n",
            "epoch: [22/50] train_loss: 0.00017 train_acc: 598.75000\n",
            "epoch: [22/50] train_loss: 0.00089 train_acc: 698.75000\n",
            "epoch: [22/50] train_loss: 0.00031 train_acc: 798.75000\n",
            "epoch: [22/50] train_loss: 0.00099 train_acc: 898.75000\n",
            "epoch: [22/50] train_loss: 0.00106 train_acc: 998.75000\n",
            "epoch: [22/50] train_loss: 0.00012 train_acc: 1098.75000\n",
            "epoch: [22/50] train_loss: 0.00005 train_acc: 1198.75000\n",
            "epoch: [22/50] train_loss: 0.00010 train_acc: 1298.75000\n",
            "epoch: [22/50] train_loss: 0.00007 train_acc: 1398.75000\n",
            "epoch: [23/50] train_loss: 0.01057 train_acc: 98.75000\n",
            "epoch: [23/50] train_loss: 0.00592 train_acc: 198.75000\n",
            "epoch: [23/50] train_loss: 0.00496 train_acc: 298.75000\n",
            "epoch: [23/50] train_loss: 0.00261 train_acc: 398.75000\n",
            "epoch: [23/50] train_loss: 0.00127 train_acc: 498.75000\n",
            "epoch: [23/50] train_loss: 0.00004 train_acc: 598.75000\n",
            "epoch: [23/50] train_loss: 0.00393 train_acc: 698.75000\n",
            "epoch: [23/50] train_loss: 0.00019 train_acc: 798.75000\n",
            "epoch: [23/50] train_loss: 0.00038 train_acc: 898.75000\n",
            "epoch: [23/50] train_loss: 0.00171 train_acc: 998.75000\n",
            "epoch: [23/50] train_loss: 0.00001 train_acc: 1098.75000\n",
            "epoch: [23/50] train_loss: 0.00001 train_acc: 1198.75000\n",
            "epoch: [23/50] train_loss: 0.00003 train_acc: 1298.75000\n",
            "epoch: [23/50] train_loss: 0.00003 train_acc: 1398.75000\n",
            "epoch: [24/50] train_loss: 0.00011 train_acc: 100.00000\n",
            "epoch: [24/50] train_loss: 0.00019 train_acc: 200.00000\n",
            "epoch: [24/50] train_loss: 0.00168 train_acc: 300.00000\n",
            "epoch: [24/50] train_loss: 0.00018 train_acc: 400.00000\n",
            "epoch: [24/50] train_loss: 0.00131 train_acc: 500.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [24/50] train_loss: 0.00006 train_acc: 700.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [24/50] train_loss: 0.00017 train_acc: 900.00000\n",
            "epoch: [24/50] train_loss: 0.00005 train_acc: 1000.00000\n",
            "epoch: [24/50] train_loss: 0.00002 train_acc: 1100.00000\n",
            "epoch: [24/50] train_loss: 0.00024 train_acc: 1200.00000\n",
            "epoch: [24/50] train_loss: 0.00012 train_acc: 1300.00000\n",
            "epoch: [24/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [25/50] train_loss: 0.00007 train_acc: 100.00000\n",
            "epoch: [25/50] train_loss: 0.00005 train_acc: 200.00000\n",
            "epoch: [25/50] train_loss: 0.00014 train_acc: 300.00000\n",
            "epoch: [25/50] train_loss: 0.00042 train_acc: 400.00000\n",
            "epoch: [25/50] train_loss: 0.00016 train_acc: 500.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [25/50] train_loss: 0.00016 train_acc: 700.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [25/50] train_loss: 0.00037 train_acc: 900.00000\n",
            "epoch: [25/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [25/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [25/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [25/50] train_loss: 0.00003 train_acc: 1300.00000\n",
            "epoch: [25/50] train_loss: 0.00004 train_acc: 1400.00000\n",
            "epoch: [26/50] train_loss: 0.00003 train_acc: 100.00000\n",
            "epoch: [26/50] train_loss: 0.00004 train_acc: 200.00000\n",
            "epoch: [26/50] train_loss: 0.00016 train_acc: 300.00000\n",
            "epoch: [26/50] train_loss: 0.00004 train_acc: 400.00000\n",
            "epoch: [26/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [26/50] train_loss: 0.00006 train_acc: 700.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [26/50] train_loss: 0.00013 train_acc: 900.00000\n",
            "epoch: [26/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [26/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [26/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [26/50] train_loss: 0.00002 train_acc: 1300.00000\n",
            "epoch: [26/50] train_loss: 0.00003 train_acc: 1400.00000\n",
            "epoch: [27/50] train_loss: 0.00002 train_acc: 100.00000\n",
            "epoch: [27/50] train_loss: 0.00003 train_acc: 200.00000\n",
            "epoch: [27/50] train_loss: 0.00006 train_acc: 300.00000\n",
            "epoch: [27/50] train_loss: 0.00004 train_acc: 400.00000\n",
            "epoch: [27/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [27/50] train_loss: 0.00004 train_acc: 700.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [27/50] train_loss: 0.00008 train_acc: 900.00000\n",
            "epoch: [27/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [27/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [27/50] train_loss: 0.00002 train_acc: 1400.00000\n",
            "epoch: [28/50] train_loss: 0.00002 train_acc: 100.00000\n",
            "epoch: [28/50] train_loss: 0.00002 train_acc: 200.00000\n",
            "epoch: [28/50] train_loss: 0.00004 train_acc: 300.00000\n",
            "epoch: [28/50] train_loss: 0.00002 train_acc: 400.00000\n",
            "epoch: [28/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [28/50] train_loss: 0.00003 train_acc: 700.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [28/50] train_loss: 0.00004 train_acc: 900.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [28/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [28/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 100.00000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 200.00000\n",
            "epoch: [29/50] train_loss: 0.00002 train_acc: 300.00000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 700.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [29/50] train_loss: 0.00002 train_acc: 900.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [30/50] train_loss: 0.00001 train_acc: 100.00000\n",
            "epoch: [30/50] train_loss: 0.00001 train_acc: 200.00000\n",
            "epoch: [30/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [30/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [30/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [30/50] train_loss: 0.00001 train_acc: 700.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [30/50] train_loss: 0.00001 train_acc: 900.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 100.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 200.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 900.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [46/50] train_loss: 0.18576 train_acc: 97.50000\n",
            "epoch: [46/50] train_loss: 0.01066 train_acc: 197.50000\n",
            "epoch: [46/50] train_loss: 0.00428 train_acc: 297.50000\n",
            "epoch: [46/50] train_loss: 0.03477 train_acc: 396.25000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 496.25000\n",
            "epoch: [46/50] train_loss: 0.06590 train_acc: 595.00000\n",
            "epoch: [46/50] train_loss: 0.05825 train_acc: 692.50000\n",
            "epoch: [46/50] train_loss: 0.00248 train_acc: 792.50000\n",
            "epoch: [46/50] train_loss: 0.00005 train_acc: 892.50000\n",
            "epoch: [46/50] train_loss: 0.00016 train_acc: 992.50000\n",
            "epoch: [46/50] train_loss: 0.00076 train_acc: 1092.50000\n",
            "epoch: [46/50] train_loss: 0.00018 train_acc: 1192.50000\n",
            "epoch: [46/50] train_loss: 0.00006 train_acc: 1292.50000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1392.50000\n",
            "epoch: [47/50] train_loss: 0.02066 train_acc: 98.75000\n",
            "epoch: [47/50] train_loss: 0.03882 train_acc: 196.25000\n",
            "epoch: [47/50] train_loss: 0.03907 train_acc: 295.00000\n",
            "epoch: [47/50] train_loss: 0.00002 train_acc: 395.00000\n",
            "epoch: [47/50] train_loss: 0.00231 train_acc: 495.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 595.00000\n",
            "epoch: [47/50] train_loss: 0.00001 train_acc: 695.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 795.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 895.00000\n",
            "epoch: [47/50] train_loss: 0.00023 train_acc: 995.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1095.00000\n",
            "epoch: [47/50] train_loss: 0.00007 train_acc: 1195.00000\n",
            "epoch: [47/50] train_loss: 0.07712 train_acc: 1293.75000\n",
            "epoch: [47/50] train_loss: 0.02193 train_acc: 1392.50000\n",
            "epoch: [48/50] train_loss: 0.00006 train_acc: 100.00000\n",
            "epoch: [48/50] train_loss: 0.28568 train_acc: 196.25000\n",
            "epoch: [48/50] train_loss: 0.00013 train_acc: 296.25000\n",
            "epoch: [48/50] train_loss: 0.00538 train_acc: 396.25000\n",
            "epoch: [48/50] train_loss: 0.00090 train_acc: 496.25000\n",
            "epoch: [48/50] train_loss: 0.00007 train_acc: 596.25000\n",
            "epoch: [48/50] train_loss: 0.00052 train_acc: 696.25000\n",
            "epoch: [48/50] train_loss: 0.00003 train_acc: 796.25000\n",
            "epoch: [48/50] train_loss: 0.00270 train_acc: 896.25000\n",
            "epoch: [48/50] train_loss: 0.00001 train_acc: 996.25000\n",
            "epoch: [48/50] train_loss: 0.00009 train_acc: 1096.25000\n",
            "epoch: [48/50] train_loss: 0.00001 train_acc: 1196.25000\n",
            "epoch: [48/50] train_loss: 0.00008 train_acc: 1296.25000\n",
            "epoch: [48/50] train_loss: 0.00003 train_acc: 1396.25000\n",
            "epoch: [49/50] train_loss: 0.00016 train_acc: 100.00000\n",
            "epoch: [49/50] train_loss: 0.00006 train_acc: 200.00000\n",
            "epoch: [49/50] train_loss: 0.00045 train_acc: 300.00000\n",
            "epoch: [49/50] train_loss: 0.00006 train_acc: 400.00000\n",
            "epoch: [49/50] train_loss: 0.00013 train_acc: 500.00000\n",
            "epoch: [49/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [49/50] train_loss: 0.00017 train_acc: 700.00000\n",
            "epoch: [49/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [49/50] train_loss: 0.00080 train_acc: 900.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [49/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [49/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [49/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [50/50] train_loss: 0.00008 train_acc: 100.00000\n",
            "epoch: [50/50] train_loss: 0.00003 train_acc: 200.00000\n",
            "epoch: [50/50] train_loss: 0.00020 train_acc: 300.00000\n",
            "epoch: [50/50] train_loss: 0.00004 train_acc: 400.00000\n",
            "epoch: [50/50] train_loss: 0.00006 train_acc: 500.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [50/50] train_loss: 0.00008 train_acc: 700.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [50/50] train_loss: 0.00033 train_acc: 900.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [50/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [50/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "learning finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    total_acc = 0.0\n",
        "    acc = 0.0\n",
        "    data = x_test.to('cuda')\n",
        "    labels = y_test.to('cuda')\n",
        "\n",
        "    for i,data in enumerate(x_test, 0):\n",
        "        data = data.to('cuda')\n",
        "        labels = y_test.to('cuda')\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        acc = accuracy(outputs, k)\n",
        "        total_acc += acc\n",
        "\n",
        "        count = i\n",
        "\n",
        "    print('avarage acc: %.5f' % (total_acc/count),'%')\n",
        "\n",
        "print('test finish!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUMxwe9Fz6mx",
        "outputId": "09e81b94-52f9-4fe6-d1ff-ed444d2589e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avarage acc: 98.61592 %\n",
            "test finish!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 층을 하나 더 늘리니 성능이  1% 정도 더 좋아졌다"
      ],
      "metadata": {
        "id": "ZWd5q1kF03b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        " \n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1) # 이번에는 필터의 개수를 2배로 늘려줬다\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1) \n",
        "        self.fc1 = nn.Linear(4096, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.reshape(-1, 4096)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model.to('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "H0A2y2PN02Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i,data in enumerate(x_train, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to('cuda')\n",
        "        labels = y_train.to('cuda')\n",
        "\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        #print(\"intpus_1 shape: \",input_1.shape)\n",
        "        #print(\"outputs shape: \",outputs.shape)\n",
        "        #print(\"labels shape\",labels.shape)\n",
        "         #labels = labels.view(len(labels),-1)\n",
        "        loss = criterion(outputs, k)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += accuracy(outputs, k)\n",
        "\n",
        "        if i % 80 == 79:\n",
        "            print('epoch: [%d/%d] train_loss: %.5f train_acc: %.5f' % (\n",
        "                epoch + 1, epochs, running_loss / 80, running_acc / 80))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"learning finish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFdbaI5N1ShD",
        "outputId": "b7490929-9620-4df4-ced5-f8c7ecd1d8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/50] train_loss: 0.69522 train_acc: 53.75000\n",
            "epoch: [1/50] train_loss: 0.69753 train_acc: 96.25000\n",
            "epoch: [1/50] train_loss: 0.63556 train_acc: 153.75000\n",
            "epoch: [1/50] train_loss: 0.45697 train_acc: 238.75000\n",
            "epoch: [1/50] train_loss: 0.31868 train_acc: 325.00000\n",
            "epoch: [1/50] train_loss: 0.34670 train_acc: 412.50000\n",
            "epoch: [1/50] train_loss: 0.20587 train_acc: 506.25000\n",
            "epoch: [1/50] train_loss: 0.23118 train_acc: 598.75000\n",
            "epoch: [1/50] train_loss: 0.16672 train_acc: 688.75000\n",
            "epoch: [1/50] train_loss: 0.24422 train_acc: 782.50000\n",
            "epoch: [1/50] train_loss: 0.11755 train_acc: 880.00000\n",
            "epoch: [1/50] train_loss: 0.07984 train_acc: 976.25000\n",
            "epoch: [1/50] train_loss: 0.10404 train_acc: 1072.50000\n",
            "epoch: [1/50] train_loss: 0.26656 train_acc: 1166.25000\n",
            "epoch: [2/50] train_loss: 0.21431 train_acc: 93.75000\n",
            "epoch: [2/50] train_loss: 0.30619 train_acc: 178.75000\n",
            "epoch: [2/50] train_loss: 0.19386 train_acc: 271.25000\n",
            "epoch: [2/50] train_loss: 0.16252 train_acc: 363.75000\n",
            "epoch: [2/50] train_loss: 0.08359 train_acc: 460.00000\n",
            "epoch: [2/50] train_loss: 0.17712 train_acc: 555.00000\n",
            "epoch: [2/50] train_loss: 0.08658 train_acc: 653.75000\n",
            "epoch: [2/50] train_loss: 0.16041 train_acc: 748.75000\n",
            "epoch: [2/50] train_loss: 0.09932 train_acc: 846.25000\n",
            "epoch: [2/50] train_loss: 0.15707 train_acc: 940.00000\n",
            "epoch: [2/50] train_loss: 0.07778 train_acc: 1038.75000\n",
            "epoch: [2/50] train_loss: 0.03270 train_acc: 1138.75000\n",
            "epoch: [2/50] train_loss: 0.08342 train_acc: 1237.50000\n",
            "epoch: [2/50] train_loss: 0.15649 train_acc: 1332.50000\n",
            "epoch: [3/50] train_loss: 0.19445 train_acc: 95.00000\n",
            "epoch: [3/50] train_loss: 0.21746 train_acc: 187.50000\n",
            "epoch: [3/50] train_loss: 0.13621 train_acc: 283.75000\n",
            "epoch: [3/50] train_loss: 0.09740 train_acc: 378.75000\n",
            "epoch: [3/50] train_loss: 0.03291 train_acc: 478.75000\n",
            "epoch: [3/50] train_loss: 0.12699 train_acc: 573.75000\n",
            "epoch: [3/50] train_loss: 0.05528 train_acc: 672.50000\n",
            "epoch: [3/50] train_loss: 0.11682 train_acc: 767.50000\n",
            "epoch: [3/50] train_loss: 0.06325 train_acc: 866.25000\n",
            "epoch: [3/50] train_loss: 0.11282 train_acc: 962.50000\n",
            "epoch: [3/50] train_loss: 0.06791 train_acc: 1060.00000\n",
            "epoch: [3/50] train_loss: 0.01526 train_acc: 1160.00000\n",
            "epoch: [3/50] train_loss: 0.07604 train_acc: 1258.75000\n",
            "epoch: [3/50] train_loss: 0.03690 train_acc: 1357.50000\n",
            "epoch: [4/50] train_loss: 0.19333 train_acc: 95.00000\n",
            "epoch: [4/50] train_loss: 0.16735 train_acc: 190.00000\n",
            "epoch: [4/50] train_loss: 0.09308 train_acc: 287.50000\n",
            "epoch: [4/50] train_loss: 0.08352 train_acc: 386.25000\n",
            "epoch: [4/50] train_loss: 0.01949 train_acc: 486.25000\n",
            "epoch: [4/50] train_loss: 0.11561 train_acc: 582.50000\n",
            "epoch: [4/50] train_loss: 0.03936 train_acc: 681.25000\n",
            "epoch: [4/50] train_loss: 0.07519 train_acc: 776.25000\n",
            "epoch: [4/50] train_loss: 0.05572 train_acc: 871.25000\n",
            "epoch: [4/50] train_loss: 0.06770 train_acc: 968.75000\n",
            "epoch: [4/50] train_loss: 0.06022 train_acc: 1066.25000\n",
            "epoch: [4/50] train_loss: 0.01200 train_acc: 1166.25000\n",
            "epoch: [4/50] train_loss: 0.06968 train_acc: 1265.00000\n",
            "epoch: [4/50] train_loss: 0.01460 train_acc: 1365.00000\n",
            "epoch: [5/50] train_loss: 0.17284 train_acc: 96.25000\n",
            "epoch: [5/50] train_loss: 0.14016 train_acc: 192.50000\n",
            "epoch: [5/50] train_loss: 0.06153 train_acc: 291.25000\n",
            "epoch: [5/50] train_loss: 0.06365 train_acc: 390.00000\n",
            "epoch: [5/50] train_loss: 0.01224 train_acc: 490.00000\n",
            "epoch: [5/50] train_loss: 0.09494 train_acc: 587.50000\n",
            "epoch: [5/50] train_loss: 0.03392 train_acc: 686.25000\n",
            "epoch: [5/50] train_loss: 0.03231 train_acc: 785.00000\n",
            "epoch: [5/50] train_loss: 0.04943 train_acc: 882.50000\n",
            "epoch: [5/50] train_loss: 0.03689 train_acc: 980.00000\n",
            "epoch: [5/50] train_loss: 0.01237 train_acc: 1080.00000\n",
            "epoch: [5/50] train_loss: 0.01226 train_acc: 1180.00000\n",
            "epoch: [5/50] train_loss: 0.03358 train_acc: 1278.75000\n",
            "epoch: [5/50] train_loss: 0.02848 train_acc: 1377.50000\n",
            "epoch: [6/50] train_loss: 0.12208 train_acc: 96.25000\n",
            "epoch: [6/50] train_loss: 0.11979 train_acc: 192.50000\n",
            "epoch: [6/50] train_loss: 0.05046 train_acc: 290.00000\n",
            "epoch: [6/50] train_loss: 0.03950 train_acc: 388.75000\n",
            "epoch: [6/50] train_loss: 0.00714 train_acc: 488.75000\n",
            "epoch: [6/50] train_loss: 0.09281 train_acc: 586.25000\n",
            "epoch: [6/50] train_loss: 0.02548 train_acc: 686.25000\n",
            "epoch: [6/50] train_loss: 0.01660 train_acc: 786.25000\n",
            "epoch: [6/50] train_loss: 0.01950 train_acc: 886.25000\n",
            "epoch: [6/50] train_loss: 0.01394 train_acc: 986.25000\n",
            "epoch: [6/50] train_loss: 0.00666 train_acc: 1086.25000\n",
            "epoch: [6/50] train_loss: 0.00441 train_acc: 1186.25000\n",
            "epoch: [6/50] train_loss: 0.00801 train_acc: 1286.25000\n",
            "epoch: [6/50] train_loss: 0.00460 train_acc: 1386.25000\n",
            "epoch: [7/50] train_loss: 0.08264 train_acc: 98.75000\n",
            "epoch: [7/50] train_loss: 0.06362 train_acc: 196.25000\n",
            "epoch: [7/50] train_loss: 0.06316 train_acc: 292.50000\n",
            "epoch: [7/50] train_loss: 0.03124 train_acc: 391.25000\n",
            "epoch: [7/50] train_loss: 0.00642 train_acc: 491.25000\n",
            "epoch: [7/50] train_loss: 0.03621 train_acc: 588.75000\n",
            "epoch: [7/50] train_loss: 0.02016 train_acc: 688.75000\n",
            "epoch: [7/50] train_loss: 0.01413 train_acc: 788.75000\n",
            "epoch: [7/50] train_loss: 0.02166 train_acc: 888.75000\n",
            "epoch: [7/50] train_loss: 0.01146 train_acc: 988.75000\n",
            "epoch: [7/50] train_loss: 0.00780 train_acc: 1088.75000\n",
            "epoch: [7/50] train_loss: 0.00326 train_acc: 1188.75000\n",
            "epoch: [7/50] train_loss: 0.00583 train_acc: 1288.75000\n",
            "epoch: [7/50] train_loss: 0.00395 train_acc: 1388.75000\n",
            "epoch: [8/50] train_loss: 0.09719 train_acc: 98.75000\n",
            "epoch: [8/50] train_loss: 0.05078 train_acc: 196.25000\n",
            "epoch: [8/50] train_loss: 0.03097 train_acc: 296.25000\n",
            "epoch: [8/50] train_loss: 0.04749 train_acc: 393.75000\n",
            "epoch: [8/50] train_loss: 0.00423 train_acc: 493.75000\n",
            "epoch: [8/50] train_loss: 0.03219 train_acc: 592.50000\n",
            "epoch: [8/50] train_loss: 0.00663 train_acc: 692.50000\n",
            "epoch: [8/50] train_loss: 0.00324 train_acc: 792.50000\n",
            "epoch: [8/50] train_loss: 0.01505 train_acc: 892.50000\n",
            "epoch: [8/50] train_loss: 0.00743 train_acc: 992.50000\n",
            "epoch: [8/50] train_loss: 0.00427 train_acc: 1092.50000\n",
            "epoch: [8/50] train_loss: 0.00224 train_acc: 1192.50000\n",
            "epoch: [8/50] train_loss: 0.00185 train_acc: 1292.50000\n",
            "epoch: [8/50] train_loss: 0.00086 train_acc: 1392.50000\n",
            "epoch: [9/50] train_loss: 0.06832 train_acc: 98.75000\n",
            "epoch: [9/50] train_loss: 0.02141 train_acc: 197.50000\n",
            "epoch: [9/50] train_loss: 0.00793 train_acc: 297.50000\n",
            "epoch: [9/50] train_loss: 0.03887 train_acc: 395.00000\n",
            "epoch: [9/50] train_loss: 0.00377 train_acc: 495.00000\n",
            "epoch: [9/50] train_loss: 0.04915 train_acc: 593.75000\n",
            "epoch: [9/50] train_loss: 0.01282 train_acc: 692.50000\n",
            "epoch: [9/50] train_loss: 0.00066 train_acc: 792.50000\n",
            "epoch: [9/50] train_loss: 0.00929 train_acc: 892.50000\n",
            "epoch: [9/50] train_loss: 0.00963 train_acc: 992.50000\n",
            "epoch: [9/50] train_loss: 0.00240 train_acc: 1092.50000\n",
            "epoch: [9/50] train_loss: 0.00154 train_acc: 1192.50000\n",
            "epoch: [9/50] train_loss: 0.00220 train_acc: 1292.50000\n",
            "epoch: [9/50] train_loss: 0.00075 train_acc: 1392.50000\n",
            "epoch: [10/50] train_loss: 0.03384 train_acc: 98.75000\n",
            "epoch: [10/50] train_loss: 0.02353 train_acc: 197.50000\n",
            "epoch: [10/50] train_loss: 0.04145 train_acc: 295.00000\n",
            "epoch: [10/50] train_loss: 0.01719 train_acc: 395.00000\n",
            "epoch: [10/50] train_loss: 0.00168 train_acc: 495.00000\n",
            "epoch: [10/50] train_loss: 0.03902 train_acc: 592.50000\n",
            "epoch: [10/50] train_loss: 0.05491 train_acc: 690.00000\n",
            "epoch: [10/50] train_loss: 0.01088 train_acc: 790.00000\n",
            "epoch: [10/50] train_loss: 0.01580 train_acc: 888.75000\n",
            "epoch: [10/50] train_loss: 0.00212 train_acc: 988.75000\n",
            "epoch: [10/50] train_loss: 0.00578 train_acc: 1088.75000\n",
            "epoch: [10/50] train_loss: 0.00155 train_acc: 1188.75000\n",
            "epoch: [10/50] train_loss: 0.00221 train_acc: 1288.75000\n",
            "epoch: [10/50] train_loss: 0.00025 train_acc: 1388.75000\n",
            "epoch: [11/50] train_loss: 0.02204 train_acc: 98.75000\n",
            "epoch: [11/50] train_loss: 0.06048 train_acc: 195.00000\n",
            "epoch: [11/50] train_loss: 0.02708 train_acc: 295.00000\n",
            "epoch: [11/50] train_loss: 0.01770 train_acc: 393.75000\n",
            "epoch: [11/50] train_loss: 0.00157 train_acc: 493.75000\n",
            "epoch: [11/50] train_loss: 0.02805 train_acc: 592.50000\n",
            "epoch: [11/50] train_loss: 0.00691 train_acc: 692.50000\n",
            "epoch: [11/50] train_loss: 0.00125 train_acc: 792.50000\n",
            "epoch: [11/50] train_loss: 0.00377 train_acc: 892.50000\n",
            "epoch: [11/50] train_loss: 0.00509 train_acc: 992.50000\n",
            "epoch: [11/50] train_loss: 0.00166 train_acc: 1092.50000\n",
            "epoch: [11/50] train_loss: 0.00035 train_acc: 1192.50000\n",
            "epoch: [11/50] train_loss: 0.00007 train_acc: 1292.50000\n",
            "epoch: [11/50] train_loss: 0.00014 train_acc: 1392.50000\n",
            "epoch: [12/50] train_loss: 0.00536 train_acc: 100.00000\n",
            "epoch: [12/50] train_loss: 0.01650 train_acc: 198.75000\n",
            "epoch: [12/50] train_loss: 0.00853 train_acc: 298.75000\n",
            "epoch: [12/50] train_loss: 0.07372 train_acc: 395.00000\n",
            "epoch: [12/50] train_loss: 0.00628 train_acc: 495.00000\n",
            "epoch: [12/50] train_loss: 0.03552 train_acc: 593.75000\n",
            "epoch: [12/50] train_loss: 0.00574 train_acc: 693.75000\n",
            "epoch: [12/50] train_loss: 0.00084 train_acc: 793.75000\n",
            "epoch: [12/50] train_loss: 0.01530 train_acc: 892.50000\n",
            "epoch: [12/50] train_loss: 0.00629 train_acc: 992.50000\n",
            "epoch: [12/50] train_loss: 0.00295 train_acc: 1092.50000\n",
            "epoch: [12/50] train_loss: 0.00033 train_acc: 1192.50000\n",
            "epoch: [12/50] train_loss: 0.00010 train_acc: 1292.50000\n",
            "epoch: [12/50] train_loss: 0.00086 train_acc: 1392.50000\n",
            "epoch: [13/50] train_loss: 0.00288 train_acc: 100.00000\n",
            "epoch: [13/50] train_loss: 0.03680 train_acc: 198.75000\n",
            "epoch: [13/50] train_loss: 0.00175 train_acc: 298.75000\n",
            "epoch: [13/50] train_loss: 0.00667 train_acc: 398.75000\n",
            "epoch: [13/50] train_loss: 0.00439 train_acc: 498.75000\n",
            "epoch: [13/50] train_loss: 0.00063 train_acc: 598.75000\n",
            "epoch: [13/50] train_loss: 0.00079 train_acc: 698.75000\n",
            "epoch: [13/50] train_loss: 0.00022 train_acc: 798.75000\n",
            "epoch: [13/50] train_loss: 0.00260 train_acc: 898.75000\n",
            "epoch: [13/50] train_loss: 0.00056 train_acc: 998.75000\n",
            "epoch: [13/50] train_loss: 0.00153 train_acc: 1098.75000\n",
            "epoch: [13/50] train_loss: 0.02714 train_acc: 1197.50000\n",
            "epoch: [13/50] train_loss: 0.14025 train_acc: 1293.75000\n",
            "epoch: [13/50] train_loss: 0.07326 train_acc: 1391.25000\n",
            "epoch: [14/50] train_loss: 0.01600 train_acc: 100.00000\n",
            "epoch: [14/50] train_loss: 0.01778 train_acc: 200.00000\n",
            "epoch: [14/50] train_loss: 0.00444 train_acc: 300.00000\n",
            "epoch: [14/50] train_loss: 0.00827 train_acc: 400.00000\n",
            "epoch: [14/50] train_loss: 0.00081 train_acc: 500.00000\n",
            "epoch: [14/50] train_loss: 0.00322 train_acc: 600.00000\n",
            "epoch: [14/50] train_loss: 0.00216 train_acc: 700.00000\n",
            "epoch: [14/50] train_loss: 0.00188 train_acc: 800.00000\n",
            "epoch: [14/50] train_loss: 0.00367 train_acc: 900.00000\n",
            "epoch: [14/50] train_loss: 0.00025 train_acc: 1000.00000\n",
            "epoch: [14/50] train_loss: 0.00021 train_acc: 1100.00000\n",
            "epoch: [14/50] train_loss: 0.00051 train_acc: 1200.00000\n",
            "epoch: [14/50] train_loss: 0.00019 train_acc: 1300.00000\n",
            "epoch: [14/50] train_loss: 0.00032 train_acc: 1400.00000\n",
            "epoch: [15/50] train_loss: 0.00335 train_acc: 100.00000\n",
            "epoch: [15/50] train_loss: 0.00273 train_acc: 200.00000\n",
            "epoch: [15/50] train_loss: 0.00191 train_acc: 300.00000\n",
            "epoch: [15/50] train_loss: 0.00151 train_acc: 400.00000\n",
            "epoch: [15/50] train_loss: 0.00045 train_acc: 500.00000\n",
            "epoch: [15/50] train_loss: 0.00003 train_acc: 600.00000\n",
            "epoch: [15/50] train_loss: 0.00018 train_acc: 700.00000\n",
            "epoch: [15/50] train_loss: 0.00049 train_acc: 800.00000\n",
            "epoch: [15/50] train_loss: 0.00080 train_acc: 900.00000\n",
            "epoch: [15/50] train_loss: 0.00015 train_acc: 1000.00000\n",
            "epoch: [15/50] train_loss: 0.00013 train_acc: 1100.00000\n",
            "epoch: [15/50] train_loss: 0.00031 train_acc: 1200.00000\n",
            "epoch: [15/50] train_loss: 0.00005 train_acc: 1300.00000\n",
            "epoch: [15/50] train_loss: 0.00021 train_acc: 1400.00000\n",
            "epoch: [16/50] train_loss: 0.00075 train_acc: 100.00000\n",
            "epoch: [16/50] train_loss: 0.00042 train_acc: 200.00000\n",
            "epoch: [16/50] train_loss: 0.00034 train_acc: 300.00000\n",
            "epoch: [16/50] train_loss: 0.00028 train_acc: 400.00000\n",
            "epoch: [16/50] train_loss: 0.00019 train_acc: 500.00000\n",
            "epoch: [16/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [16/50] train_loss: 0.00016 train_acc: 700.00000\n",
            "epoch: [16/50] train_loss: 0.00009 train_acc: 800.00000\n",
            "epoch: [16/50] train_loss: 0.00040 train_acc: 900.00000\n",
            "epoch: [16/50] train_loss: 0.00004 train_acc: 1000.00000\n",
            "epoch: [16/50] train_loss: 0.00005 train_acc: 1100.00000\n",
            "epoch: [16/50] train_loss: 0.00004 train_acc: 1200.00000\n",
            "epoch: [16/50] train_loss: 0.00003 train_acc: 1300.00000\n",
            "epoch: [16/50] train_loss: 0.00011 train_acc: 1400.00000\n",
            "epoch: [17/50] train_loss: 0.00028 train_acc: 100.00000\n",
            "epoch: [17/50] train_loss: 0.00025 train_acc: 200.00000\n",
            "epoch: [17/50] train_loss: 0.00016 train_acc: 300.00000\n",
            "epoch: [17/50] train_loss: 0.00013 train_acc: 400.00000\n",
            "epoch: [17/50] train_loss: 0.00006 train_acc: 500.00000\n",
            "epoch: [17/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [17/50] train_loss: 0.00007 train_acc: 700.00000\n",
            "epoch: [17/50] train_loss: 0.00004 train_acc: 800.00000\n",
            "epoch: [17/50] train_loss: 0.00013 train_acc: 900.00000\n",
            "epoch: [17/50] train_loss: 0.00002 train_acc: 1000.00000\n",
            "epoch: [17/50] train_loss: 0.00003 train_acc: 1100.00000\n",
            "epoch: [17/50] train_loss: 0.00002 train_acc: 1200.00000\n",
            "epoch: [17/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [17/50] train_loss: 0.00005 train_acc: 1400.00000\n",
            "epoch: [18/50] train_loss: 0.00013 train_acc: 100.00000\n",
            "epoch: [18/50] train_loss: 0.00012 train_acc: 200.00000\n",
            "epoch: [18/50] train_loss: 0.00007 train_acc: 300.00000\n",
            "epoch: [18/50] train_loss: 0.00007 train_acc: 400.00000\n",
            "epoch: [18/50] train_loss: 0.00002 train_acc: 500.00000\n",
            "epoch: [18/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [18/50] train_loss: 0.00004 train_acc: 700.00000\n",
            "epoch: [18/50] train_loss: 0.00002 train_acc: 800.00000\n",
            "epoch: [18/50] train_loss: 0.00007 train_acc: 900.00000\n",
            "epoch: [18/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [18/50] train_loss: 0.00002 train_acc: 1100.00000\n",
            "epoch: [18/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [18/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [18/50] train_loss: 0.00002 train_acc: 1400.00000\n",
            "epoch: [19/50] train_loss: 0.00007 train_acc: 100.00000\n",
            "epoch: [19/50] train_loss: 0.00007 train_acc: 200.00000\n",
            "epoch: [19/50] train_loss: 0.00004 train_acc: 300.00000\n",
            "epoch: [19/50] train_loss: 0.00004 train_acc: 400.00000\n",
            "epoch: [19/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [19/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [19/50] train_loss: 0.00002 train_acc: 700.00000\n",
            "epoch: [19/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [19/50] train_loss: 0.00004 train_acc: 900.00000\n",
            "epoch: [19/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [19/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [19/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [19/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [19/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [20/50] train_loss: 0.00004 train_acc: 100.00000\n",
            "epoch: [20/50] train_loss: 0.00003 train_acc: 200.00000\n",
            "epoch: [20/50] train_loss: 0.00002 train_acc: 300.00000\n",
            "epoch: [20/50] train_loss: 0.00002 train_acc: 400.00000\n",
            "epoch: [20/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [20/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [20/50] train_loss: 0.00001 train_acc: 700.00000\n",
            "epoch: [20/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [20/50] train_loss: 0.00002 train_acc: 900.00000\n",
            "epoch: [20/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [20/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [20/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [20/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [20/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [21/50] train_loss: 0.00002 train_acc: 100.00000\n",
            "epoch: [21/50] train_loss: 0.00002 train_acc: 200.00000\n",
            "epoch: [21/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [21/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [21/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [21/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [21/50] train_loss: 0.00001 train_acc: 700.00000\n",
            "epoch: [21/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [21/50] train_loss: 0.00001 train_acc: 900.00000\n",
            "epoch: [21/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [21/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [21/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [21/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [21/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 100.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 200.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 700.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 900.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [23/50] train_loss: 0.00001 train_acc: 100.00000\n",
            "epoch: [23/50] train_loss: 0.00001 train_acc: 200.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [24/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [25/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [26/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [27/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [28/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [37/50] train_loss: 0.44130 train_acc: 898.75000\n",
            "epoch: [37/50] train_loss: 0.07313 train_acc: 997.50000\n",
            "epoch: [37/50] train_loss: 0.16052 train_acc: 1096.25000\n",
            "epoch: [37/50] train_loss: 0.00017 train_acc: 1196.25000\n",
            "epoch: [37/50] train_loss: 0.04243 train_acc: 1295.00000\n",
            "epoch: [37/50] train_loss: 0.00084 train_acc: 1395.00000\n",
            "epoch: [38/50] train_loss: 0.25201 train_acc: 96.25000\n",
            "epoch: [38/50] train_loss: 0.12131 train_acc: 193.75000\n",
            "epoch: [38/50] train_loss: 0.31906 train_acc: 292.50000\n",
            "epoch: [38/50] train_loss: 0.00268 train_acc: 392.50000\n",
            "epoch: [38/50] train_loss: 0.00441 train_acc: 492.50000\n",
            "epoch: [38/50] train_loss: 0.00009 train_acc: 592.50000\n",
            "epoch: [38/50] train_loss: 0.00008 train_acc: 692.50000\n",
            "epoch: [38/50] train_loss: 0.00046 train_acc: 792.50000\n",
            "epoch: [38/50] train_loss: 0.00159 train_acc: 892.50000\n",
            "epoch: [38/50] train_loss: 0.00078 train_acc: 992.50000\n",
            "epoch: [38/50] train_loss: 0.00007 train_acc: 1092.50000\n",
            "epoch: [38/50] train_loss: 0.00001 train_acc: 1192.50000\n",
            "epoch: [38/50] train_loss: 0.00038 train_acc: 1292.50000\n",
            "epoch: [38/50] train_loss: 0.00007 train_acc: 1392.50000\n",
            "epoch: [39/50] train_loss: 0.01113 train_acc: 98.75000\n",
            "epoch: [39/50] train_loss: 0.00436 train_acc: 198.75000\n",
            "epoch: [39/50] train_loss: 0.00001 train_acc: 298.75000\n",
            "epoch: [39/50] train_loss: 0.00293 train_acc: 398.75000\n",
            "epoch: [39/50] train_loss: 0.00002 train_acc: 498.75000\n",
            "epoch: [39/50] train_loss: 0.00155 train_acc: 598.75000\n",
            "epoch: [39/50] train_loss: 0.00021 train_acc: 698.75000\n",
            "epoch: [39/50] train_loss: 0.00003 train_acc: 798.75000\n",
            "epoch: [39/50] train_loss: 0.00061 train_acc: 898.75000\n",
            "epoch: [39/50] train_loss: 0.00086 train_acc: 998.75000\n",
            "epoch: [39/50] train_loss: 0.00007 train_acc: 1098.75000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1198.75000\n",
            "epoch: [39/50] train_loss: 0.00009 train_acc: 1298.75000\n",
            "epoch: [39/50] train_loss: 0.00018 train_acc: 1398.75000\n",
            "epoch: [40/50] train_loss: 0.00004 train_acc: 100.00000\n",
            "epoch: [40/50] train_loss: 0.00025 train_acc: 200.00000\n",
            "epoch: [40/50] train_loss: 0.00009 train_acc: 300.00000\n",
            "epoch: [40/50] train_loss: 0.00005 train_acc: 400.00000\n",
            "epoch: [40/50] train_loss: 0.00003 train_acc: 500.00000\n",
            "epoch: [40/50] train_loss: 0.00003 train_acc: 600.00000\n",
            "epoch: [40/50] train_loss: 0.00009 train_acc: 700.00000\n",
            "epoch: [40/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [40/50] train_loss: 0.00030 train_acc: 900.00000\n",
            "epoch: [40/50] train_loss: 0.00010 train_acc: 1000.00000\n",
            "epoch: [40/50] train_loss: 0.00003 train_acc: 1100.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [40/50] train_loss: 0.00007 train_acc: 1300.00000\n",
            "epoch: [40/50] train_loss: 0.00007 train_acc: 1400.00000\n",
            "epoch: [41/50] train_loss: 0.00003 train_acc: 100.00000\n",
            "epoch: [41/50] train_loss: 0.00017 train_acc: 200.00000\n",
            "epoch: [41/50] train_loss: 0.00004 train_acc: 300.00000\n",
            "epoch: [41/50] train_loss: 0.00003 train_acc: 400.00000\n",
            "epoch: [41/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [41/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [41/50] train_loss: 0.00005 train_acc: 700.00000\n",
            "epoch: [41/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [41/50] train_loss: 0.00016 train_acc: 900.00000\n",
            "epoch: [41/50] train_loss: 0.00006 train_acc: 1000.00000\n",
            "epoch: [41/50] train_loss: 0.00002 train_acc: 1100.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [41/50] train_loss: 0.00003 train_acc: 1300.00000\n",
            "epoch: [41/50] train_loss: 0.00004 train_acc: 1400.00000\n",
            "epoch: [42/50] train_loss: 0.00002 train_acc: 100.00000\n",
            "epoch: [42/50] train_loss: 0.00009 train_acc: 200.00000\n",
            "epoch: [42/50] train_loss: 0.00002 train_acc: 300.00000\n",
            "epoch: [42/50] train_loss: 0.00002 train_acc: 400.00000\n",
            "epoch: [42/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [42/50] train_loss: 0.00003 train_acc: 700.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [42/50] train_loss: 0.00008 train_acc: 900.00000\n",
            "epoch: [42/50] train_loss: 0.00003 train_acc: 1000.00000\n",
            "epoch: [42/50] train_loss: 0.00001 train_acc: 1100.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [42/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [42/50] train_loss: 0.00002 train_acc: 1400.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 100.00000\n",
            "epoch: [43/50] train_loss: 0.00005 train_acc: 200.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 700.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [43/50] train_loss: 0.00005 train_acc: 900.00000\n",
            "epoch: [43/50] train_loss: 0.00002 train_acc: 1000.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 1300.00000\n",
            "epoch: [43/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [44/50] train_loss: 0.00003 train_acc: 200.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 700.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [44/50] train_loss: 0.00002 train_acc: 900.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [44/50] train_loss: 0.00001 train_acc: 1400.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [45/50] train_loss: 0.00001 train_acc: 200.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [45/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [45/50] train_loss: 0.00001 train_acc: 900.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [46/50] train_loss: 0.00001 train_acc: 200.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [46/50] train_loss: 0.00001 train_acc: 900.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "learning finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    total_acc = 0.0\n",
        "    acc = 0.0\n",
        "    data = x_test.to('cuda')\n",
        "    labels = y_test.to('cuda')\n",
        "\n",
        "    for i,data in enumerate(x_test, 0):\n",
        "        data = data.to('cuda')\n",
        "        labels = y_test.to('cuda')\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        acc = accuracy(outputs, k)\n",
        "        total_acc += acc\n",
        "\n",
        "        count = i\n",
        "\n",
        "    print('avarage acc: %.5f' % (total_acc/count),'%')\n",
        "\n",
        "print('test finish!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAFK-dFq1VFd",
        "outputId": "3f97c52b-3446-4014-97ee-ff99a2d63557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avarage acc: 98.96194 %\n",
            "test finish!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정확도가 살짝오름"
      ],
      "metadata": {
        "id": "GDr8FiQ49QTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#learning_rate: 기울기에 곱해서 얼만큼 이동할지 결정해줌"
      ],
      "metadata": {
        "id": "uAPntnHw96oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        " \n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1) # 이번에는 필터의 개수를 2배로 늘려줬다\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1) \n",
        "        self.fc1 = nn.Linear(4096, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.reshape(-1, 4096)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model.to('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # 0.0001에서 0.001로 해줌 한번 바꿀때 이전보다 값이 더 많이 바뀌게 될 거다 \n",
        "\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "08UQSaKd9NvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i,data in enumerate(x_train, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to('cuda')\n",
        "        labels = y_train.to('cuda')\n",
        "\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        #print(\"intpus_1 shape: \",input_1.shape)\n",
        "        #print(\"outputs shape: \",outputs.shape)\n",
        "        #print(\"labels shape\",labels.shape)\n",
        "         #labels = labels.view(len(labels),-1)\n",
        "        loss = criterion(outputs, k)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += accuracy(outputs, k)\n",
        "\n",
        "        if i % 80 == 79:\n",
        "            print('epoch: [%d/%d] train_loss: %.5f train_acc: %.5f' % (\n",
        "                epoch + 1, epochs, running_loss / 80, running_acc / 80))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"learning finish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0zljN8B-Hzh",
        "outputId": "ab05a27c-024b-4552-ad17-d59d446e07c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/50] train_loss: 0.72822 train_acc: 45.00000\n",
            "epoch: [1/50] train_loss: 0.69280 train_acc: 100.00000\n",
            "epoch: [1/50] train_loss: 0.69423 train_acc: 141.25000\n",
            "epoch: [1/50] train_loss: 0.69345 train_acc: 193.75000\n",
            "epoch: [1/50] train_loss: 0.69428 train_acc: 237.50000\n",
            "epoch: [1/50] train_loss: 0.69290 train_acc: 292.50000\n",
            "epoch: [1/50] train_loss: 0.69472 train_acc: 338.75000\n",
            "epoch: [1/50] train_loss: 0.69080 train_acc: 398.75000\n",
            "epoch: [1/50] train_loss: 0.69351 train_acc: 450.00000\n",
            "epoch: [1/50] train_loss: 0.69537 train_acc: 496.25000\n",
            "epoch: [1/50] train_loss: 0.69399 train_acc: 545.00000\n",
            "epoch: [1/50] train_loss: 0.69614 train_acc: 595.00000\n",
            "epoch: [1/50] train_loss: 0.69865 train_acc: 648.75000\n",
            "epoch: [1/50] train_loss: 0.69626 train_acc: 695.00000\n",
            "epoch: [2/50] train_loss: 0.85056 train_acc: 56.25000\n",
            "epoch: [2/50] train_loss: 0.79501 train_acc: 122.50000\n",
            "epoch: [2/50] train_loss: 0.63800 train_acc: 202.50000\n",
            "epoch: [2/50] train_loss: 0.64248 train_acc: 272.50000\n",
            "epoch: [2/50] train_loss: 0.46650 train_acc: 350.00000\n",
            "epoch: [2/50] train_loss: 0.38013 train_acc: 440.00000\n",
            "epoch: [2/50] train_loss: 0.37610 train_acc: 520.00000\n",
            "epoch: [2/50] train_loss: 0.33340 train_acc: 608.75000\n",
            "epoch: [2/50] train_loss: 0.39114 train_acc: 695.00000\n",
            "epoch: [2/50] train_loss: 0.30964 train_acc: 783.75000\n",
            "epoch: [2/50] train_loss: 0.17485 train_acc: 877.50000\n",
            "epoch: [2/50] train_loss: 0.19116 train_acc: 972.50000\n",
            "epoch: [2/50] train_loss: 0.12150 train_acc: 1070.00000\n",
            "epoch: [2/50] train_loss: 0.31421 train_acc: 1158.75000\n",
            "epoch: [3/50] train_loss: 0.37890 train_acc: 87.50000\n",
            "epoch: [3/50] train_loss: 0.32871 train_acc: 175.00000\n",
            "epoch: [3/50] train_loss: 0.25239 train_acc: 267.50000\n",
            "epoch: [3/50] train_loss: 0.35694 train_acc: 358.75000\n",
            "epoch: [3/50] train_loss: 0.17662 train_acc: 452.50000\n",
            "epoch: [3/50] train_loss: 0.15123 train_acc: 548.75000\n",
            "epoch: [3/50] train_loss: 0.12330 train_acc: 645.00000\n",
            "epoch: [3/50] train_loss: 0.36351 train_acc: 736.25000\n",
            "epoch: [3/50] train_loss: 0.11502 train_acc: 832.50000\n",
            "epoch: [3/50] train_loss: 0.10810 train_acc: 928.75000\n",
            "epoch: [3/50] train_loss: 0.11951 train_acc: 1026.25000\n",
            "epoch: [3/50] train_loss: 0.06861 train_acc: 1122.50000\n",
            "epoch: [3/50] train_loss: 0.20131 train_acc: 1217.50000\n",
            "epoch: [3/50] train_loss: 0.11706 train_acc: 1312.50000\n",
            "epoch: [4/50] train_loss: 0.46468 train_acc: 96.25000\n",
            "epoch: [4/50] train_loss: 0.25094 train_acc: 191.25000\n",
            "epoch: [4/50] train_loss: 0.18613 train_acc: 282.50000\n",
            "epoch: [4/50] train_loss: 0.13632 train_acc: 377.50000\n",
            "epoch: [4/50] train_loss: 0.06086 train_acc: 472.50000\n",
            "epoch: [4/50] train_loss: 0.16864 train_acc: 567.50000\n",
            "epoch: [4/50] train_loss: 0.05035 train_acc: 666.25000\n",
            "epoch: [4/50] train_loss: 0.19333 train_acc: 758.75000\n",
            "epoch: [4/50] train_loss: 0.11156 train_acc: 853.75000\n",
            "epoch: [4/50] train_loss: 0.07923 train_acc: 952.50000\n",
            "epoch: [4/50] train_loss: 0.02578 train_acc: 1052.50000\n",
            "epoch: [4/50] train_loss: 0.00737 train_acc: 1152.50000\n",
            "epoch: [4/50] train_loss: 0.11804 train_acc: 1251.25000\n",
            "epoch: [4/50] train_loss: 0.05444 train_acc: 1350.00000\n",
            "epoch: [5/50] train_loss: 0.18486 train_acc: 95.00000\n",
            "epoch: [5/50] train_loss: 0.16338 train_acc: 187.50000\n",
            "epoch: [5/50] train_loss: 0.12252 train_acc: 282.50000\n",
            "epoch: [5/50] train_loss: 0.09301 train_acc: 377.50000\n",
            "epoch: [5/50] train_loss: 0.04351 train_acc: 475.00000\n",
            "epoch: [5/50] train_loss: 0.12039 train_acc: 572.50000\n",
            "epoch: [5/50] train_loss: 0.03685 train_acc: 672.50000\n",
            "epoch: [5/50] train_loss: 0.11169 train_acc: 768.75000\n",
            "epoch: [5/50] train_loss: 0.02648 train_acc: 867.50000\n",
            "epoch: [5/50] train_loss: 0.05313 train_acc: 966.25000\n",
            "epoch: [5/50] train_loss: 0.07634 train_acc: 1061.25000\n",
            "epoch: [5/50] train_loss: 0.01505 train_acc: 1161.25000\n",
            "epoch: [5/50] train_loss: 0.12608 train_acc: 1258.75000\n",
            "epoch: [5/50] train_loss: 0.01001 train_acc: 1358.75000\n",
            "epoch: [6/50] train_loss: 0.09424 train_acc: 96.25000\n",
            "epoch: [6/50] train_loss: 0.23681 train_acc: 190.00000\n",
            "epoch: [6/50] train_loss: 0.13763 train_acc: 286.25000\n",
            "epoch: [6/50] train_loss: 0.05695 train_acc: 383.75000\n",
            "epoch: [6/50] train_loss: 0.05395 train_acc: 482.50000\n",
            "epoch: [6/50] train_loss: 0.12997 train_acc: 580.00000\n",
            "epoch: [6/50] train_loss: 0.01333 train_acc: 680.00000\n",
            "epoch: [6/50] train_loss: 0.59773 train_acc: 770.00000\n",
            "epoch: [6/50] train_loss: 0.13928 train_acc: 865.00000\n",
            "epoch: [6/50] train_loss: 0.11801 train_acc: 960.00000\n",
            "epoch: [6/50] train_loss: 0.02086 train_acc: 1058.75000\n",
            "epoch: [6/50] train_loss: 0.05639 train_acc: 1155.00000\n",
            "epoch: [6/50] train_loss: 0.05501 train_acc: 1253.75000\n",
            "epoch: [6/50] train_loss: 0.01013 train_acc: 1353.75000\n",
            "epoch: [7/50] train_loss: 0.10897 train_acc: 95.00000\n",
            "epoch: [7/50] train_loss: 0.22178 train_acc: 187.50000\n",
            "epoch: [7/50] train_loss: 0.23650 train_acc: 280.00000\n",
            "epoch: [7/50] train_loss: 0.12084 train_acc: 375.00000\n",
            "epoch: [7/50] train_loss: 0.02053 train_acc: 475.00000\n",
            "epoch: [7/50] train_loss: 0.04324 train_acc: 572.50000\n",
            "epoch: [7/50] train_loss: 0.06680 train_acc: 668.75000\n",
            "epoch: [7/50] train_loss: 0.12477 train_acc: 766.25000\n",
            "epoch: [7/50] train_loss: 0.06480 train_acc: 862.50000\n",
            "epoch: [7/50] train_loss: 0.04116 train_acc: 961.25000\n",
            "epoch: [7/50] train_loss: 0.00936 train_acc: 1061.25000\n",
            "epoch: [7/50] train_loss: 0.03872 train_acc: 1160.00000\n",
            "epoch: [7/50] train_loss: 0.05508 train_acc: 1258.75000\n",
            "epoch: [7/50] train_loss: 0.01253 train_acc: 1358.75000\n",
            "epoch: [8/50] train_loss: 0.11721 train_acc: 96.25000\n",
            "epoch: [8/50] train_loss: 0.15894 train_acc: 192.50000\n",
            "epoch: [8/50] train_loss: 0.09437 train_acc: 290.00000\n",
            "epoch: [8/50] train_loss: 0.01972 train_acc: 390.00000\n",
            "epoch: [8/50] train_loss: 0.00490 train_acc: 490.00000\n",
            "epoch: [8/50] train_loss: 0.07855 train_acc: 588.75000\n",
            "epoch: [8/50] train_loss: 0.07287 train_acc: 685.00000\n",
            "epoch: [8/50] train_loss: 0.12827 train_acc: 780.00000\n",
            "epoch: [8/50] train_loss: 0.02161 train_acc: 878.75000\n",
            "epoch: [8/50] train_loss: 0.03092 train_acc: 976.25000\n",
            "epoch: [8/50] train_loss: 0.01073 train_acc: 1076.25000\n",
            "epoch: [8/50] train_loss: 0.00883 train_acc: 1176.25000\n",
            "epoch: [8/50] train_loss: 0.00427 train_acc: 1276.25000\n",
            "epoch: [8/50] train_loss: 0.00108 train_acc: 1376.25000\n",
            "epoch: [9/50] train_loss: 0.26727 train_acc: 91.25000\n",
            "epoch: [9/50] train_loss: 0.18376 train_acc: 186.25000\n",
            "epoch: [9/50] train_loss: 0.08753 train_acc: 283.75000\n",
            "epoch: [9/50] train_loss: 0.03112 train_acc: 382.50000\n",
            "epoch: [9/50] train_loss: 0.17719 train_acc: 477.50000\n",
            "epoch: [9/50] train_loss: 0.08098 train_acc: 576.25000\n",
            "epoch: [9/50] train_loss: 0.21663 train_acc: 668.75000\n",
            "epoch: [9/50] train_loss: 0.03563 train_acc: 767.50000\n",
            "epoch: [9/50] train_loss: 0.11949 train_acc: 863.75000\n",
            "epoch: [9/50] train_loss: 0.05875 train_acc: 961.25000\n",
            "epoch: [9/50] train_loss: 0.00160 train_acc: 1061.25000\n",
            "epoch: [9/50] train_loss: 0.00055 train_acc: 1161.25000\n",
            "epoch: [9/50] train_loss: 0.01888 train_acc: 1260.00000\n",
            "epoch: [9/50] train_loss: 0.03201 train_acc: 1358.75000\n",
            "epoch: [10/50] train_loss: 0.25294 train_acc: 96.25000\n",
            "epoch: [10/50] train_loss: 0.17167 train_acc: 193.75000\n",
            "epoch: [10/50] train_loss: 0.15898 train_acc: 288.75000\n",
            "epoch: [10/50] train_loss: 0.04670 train_acc: 387.50000\n",
            "epoch: [10/50] train_loss: 0.00634 train_acc: 487.50000\n",
            "epoch: [10/50] train_loss: 0.15566 train_acc: 586.25000\n",
            "epoch: [10/50] train_loss: 0.01549 train_acc: 686.25000\n",
            "epoch: [10/50] train_loss: 0.04550 train_acc: 783.75000\n",
            "epoch: [10/50] train_loss: 0.02484 train_acc: 882.50000\n",
            "epoch: [10/50] train_loss: 0.03721 train_acc: 981.25000\n",
            "epoch: [10/50] train_loss: 0.05667 train_acc: 1080.00000\n",
            "epoch: [10/50] train_loss: 0.00839 train_acc: 1180.00000\n",
            "epoch: [10/50] train_loss: 0.00660 train_acc: 1280.00000\n",
            "epoch: [10/50] train_loss: 0.00065 train_acc: 1380.00000\n",
            "epoch: [11/50] train_loss: 0.09842 train_acc: 97.50000\n",
            "epoch: [11/50] train_loss: 0.12605 train_acc: 193.75000\n",
            "epoch: [11/50] train_loss: 0.05351 train_acc: 292.50000\n",
            "epoch: [11/50] train_loss: 0.03799 train_acc: 391.25000\n",
            "epoch: [11/50] train_loss: 0.08248 train_acc: 488.75000\n",
            "epoch: [11/50] train_loss: 0.06082 train_acc: 586.25000\n",
            "epoch: [11/50] train_loss: 0.00830 train_acc: 686.25000\n",
            "epoch: [11/50] train_loss: 0.01056 train_acc: 785.00000\n",
            "epoch: [11/50] train_loss: 0.07231 train_acc: 882.50000\n",
            "epoch: [11/50] train_loss: 0.06892 train_acc: 981.25000\n",
            "epoch: [11/50] train_loss: 0.01388 train_acc: 1081.25000\n",
            "epoch: [11/50] train_loss: 0.00445 train_acc: 1181.25000\n",
            "epoch: [11/50] train_loss: 0.00377 train_acc: 1281.25000\n",
            "epoch: [11/50] train_loss: 0.00149 train_acc: 1381.25000\n",
            "epoch: [12/50] train_loss: 0.01524 train_acc: 98.75000\n",
            "epoch: [12/50] train_loss: 0.09546 train_acc: 196.25000\n",
            "epoch: [12/50] train_loss: 0.04220 train_acc: 295.00000\n",
            "epoch: [12/50] train_loss: 0.01071 train_acc: 395.00000\n",
            "epoch: [12/50] train_loss: 0.00386 train_acc: 495.00000\n",
            "epoch: [12/50] train_loss: 0.02839 train_acc: 593.75000\n",
            "epoch: [12/50] train_loss: 0.08903 train_acc: 691.25000\n",
            "epoch: [12/50] train_loss: 0.04534 train_acc: 790.00000\n",
            "epoch: [12/50] train_loss: 0.00525 train_acc: 890.00000\n",
            "epoch: [12/50] train_loss: 0.06499 train_acc: 987.50000\n",
            "epoch: [12/50] train_loss: 0.00811 train_acc: 1087.50000\n",
            "epoch: [12/50] train_loss: 0.10682 train_acc: 1186.25000\n",
            "epoch: [12/50] train_loss: 0.15342 train_acc: 1283.75000\n",
            "epoch: [12/50] train_loss: 0.00478 train_acc: 1383.75000\n",
            "epoch: [13/50] train_loss: 0.01292 train_acc: 98.75000\n",
            "epoch: [13/50] train_loss: 0.37106 train_acc: 192.50000\n",
            "epoch: [13/50] train_loss: 0.08635 train_acc: 288.75000\n",
            "epoch: [13/50] train_loss: 0.00790 train_acc: 388.75000\n",
            "epoch: [13/50] train_loss: 0.00549 train_acc: 488.75000\n",
            "epoch: [13/50] train_loss: 0.08172 train_acc: 587.50000\n",
            "epoch: [13/50] train_loss: 0.01219 train_acc: 687.50000\n",
            "epoch: [13/50] train_loss: 0.01702 train_acc: 787.50000\n",
            "epoch: [13/50] train_loss: 0.00290 train_acc: 887.50000\n",
            "epoch: [13/50] train_loss: 0.00592 train_acc: 987.50000\n",
            "epoch: [13/50] train_loss: 0.06074 train_acc: 1085.00000\n",
            "epoch: [13/50] train_loss: 0.00135 train_acc: 1185.00000\n",
            "epoch: [13/50] train_loss: 0.00922 train_acc: 1285.00000\n",
            "epoch: [13/50] train_loss: 0.00126 train_acc: 1385.00000\n",
            "epoch: [14/50] train_loss: 0.10995 train_acc: 97.50000\n",
            "epoch: [14/50] train_loss: 0.17235 train_acc: 193.75000\n",
            "epoch: [14/50] train_loss: 0.17232 train_acc: 287.50000\n",
            "epoch: [14/50] train_loss: 0.03338 train_acc: 386.25000\n",
            "epoch: [14/50] train_loss: 0.02513 train_acc: 485.00000\n",
            "epoch: [14/50] train_loss: 0.06900 train_acc: 583.75000\n",
            "epoch: [14/50] train_loss: 0.00386 train_acc: 683.75000\n",
            "epoch: [14/50] train_loss: 0.00803 train_acc: 783.75000\n",
            "epoch: [14/50] train_loss: 0.00985 train_acc: 883.75000\n",
            "epoch: [14/50] train_loss: 0.01912 train_acc: 982.50000\n",
            "epoch: [14/50] train_loss: 0.00779 train_acc: 1082.50000\n",
            "epoch: [14/50] train_loss: 0.00026 train_acc: 1182.50000\n",
            "epoch: [14/50] train_loss: 0.01040 train_acc: 1281.25000\n",
            "epoch: [14/50] train_loss: 0.00046 train_acc: 1381.25000\n",
            "epoch: [15/50] train_loss: 0.06088 train_acc: 97.50000\n",
            "epoch: [15/50] train_loss: 0.34030 train_acc: 190.00000\n",
            "epoch: [15/50] train_loss: 0.08201 train_acc: 287.50000\n",
            "epoch: [15/50] train_loss: 0.01041 train_acc: 387.50000\n",
            "epoch: [15/50] train_loss: 0.00112 train_acc: 487.50000\n",
            "epoch: [15/50] train_loss: 0.06904 train_acc: 586.25000\n",
            "epoch: [15/50] train_loss: 0.04130 train_acc: 685.00000\n",
            "epoch: [15/50] train_loss: 0.00058 train_acc: 785.00000\n",
            "epoch: [15/50] train_loss: 0.03012 train_acc: 883.75000\n",
            "epoch: [15/50] train_loss: 0.01460 train_acc: 982.50000\n",
            "epoch: [15/50] train_loss: 0.17513 train_acc: 1081.25000\n",
            "epoch: [15/50] train_loss: 0.00201 train_acc: 1181.25000\n",
            "epoch: [15/50] train_loss: 0.05127 train_acc: 1278.75000\n",
            "epoch: [15/50] train_loss: 0.01404 train_acc: 1377.50000\n",
            "epoch: [16/50] train_loss: 0.00418 train_acc: 100.00000\n",
            "epoch: [16/50] train_loss: 0.19955 train_acc: 195.00000\n",
            "epoch: [16/50] train_loss: 0.04725 train_acc: 293.75000\n",
            "epoch: [16/50] train_loss: 0.07332 train_acc: 392.50000\n",
            "epoch: [16/50] train_loss: 0.00496 train_acc: 492.50000\n",
            "epoch: [16/50] train_loss: 0.18883 train_acc: 590.00000\n",
            "epoch: [16/50] train_loss: 0.02011 train_acc: 688.75000\n",
            "epoch: [16/50] train_loss: 0.00013 train_acc: 788.75000\n",
            "epoch: [16/50] train_loss: 0.02963 train_acc: 887.50000\n",
            "epoch: [16/50] train_loss: 0.00063 train_acc: 987.50000\n",
            "epoch: [16/50] train_loss: 0.00034 train_acc: 1087.50000\n",
            "epoch: [16/50] train_loss: 0.01183 train_acc: 1186.25000\n",
            "epoch: [16/50] train_loss: 0.03725 train_acc: 1285.00000\n",
            "epoch: [16/50] train_loss: 0.00052 train_acc: 1385.00000\n",
            "epoch: [17/50] train_loss: 0.01970 train_acc: 98.75000\n",
            "epoch: [17/50] train_loss: 0.19850 train_acc: 196.25000\n",
            "epoch: [17/50] train_loss: 0.45976 train_acc: 292.50000\n",
            "epoch: [17/50] train_loss: 0.05871 train_acc: 390.00000\n",
            "epoch: [17/50] train_loss: 0.01260 train_acc: 490.00000\n",
            "epoch: [17/50] train_loss: 0.00915 train_acc: 590.00000\n",
            "epoch: [17/50] train_loss: 0.01889 train_acc: 688.75000\n",
            "epoch: [17/50] train_loss: 0.00030 train_acc: 788.75000\n",
            "epoch: [17/50] train_loss: 0.00630 train_acc: 888.75000\n",
            "epoch: [17/50] train_loss: 0.00436 train_acc: 988.75000\n",
            "epoch: [17/50] train_loss: 0.03567 train_acc: 1087.50000\n",
            "epoch: [17/50] train_loss: 0.15941 train_acc: 1185.00000\n",
            "epoch: [17/50] train_loss: 0.52470 train_acc: 1280.00000\n",
            "epoch: [17/50] train_loss: 0.00002 train_acc: 1380.00000\n",
            "epoch: [18/50] train_loss: 0.01060 train_acc: 100.00000\n",
            "epoch: [18/50] train_loss: 0.17354 train_acc: 193.75000\n",
            "epoch: [18/50] train_loss: 0.01563 train_acc: 292.50000\n",
            "epoch: [18/50] train_loss: 0.01371 train_acc: 391.25000\n",
            "epoch: [18/50] train_loss: 0.00414 train_acc: 491.25000\n",
            "epoch: [18/50] train_loss: 0.05296 train_acc: 590.00000\n",
            "epoch: [18/50] train_loss: 0.23492 train_acc: 687.50000\n",
            "epoch: [18/50] train_loss: 0.01238 train_acc: 786.25000\n",
            "epoch: [18/50] train_loss: 0.18053 train_acc: 882.50000\n",
            "epoch: [18/50] train_loss: 0.01438 train_acc: 982.50000\n",
            "epoch: [18/50] train_loss: 0.05888 train_acc: 1081.25000\n",
            "epoch: [18/50] train_loss: 0.00142 train_acc: 1181.25000\n",
            "epoch: [18/50] train_loss: 0.04639 train_acc: 1280.00000\n",
            "epoch: [18/50] train_loss: 0.03891 train_acc: 1377.50000\n",
            "epoch: [19/50] train_loss: 0.15345 train_acc: 95.00000\n",
            "epoch: [19/50] train_loss: 0.02591 train_acc: 193.75000\n",
            "epoch: [19/50] train_loss: 0.12966 train_acc: 291.25000\n",
            "epoch: [19/50] train_loss: 0.00308 train_acc: 391.25000\n",
            "epoch: [19/50] train_loss: 0.19014 train_acc: 488.75000\n",
            "epoch: [19/50] train_loss: 0.12889 train_acc: 587.50000\n",
            "epoch: [19/50] train_loss: 0.03351 train_acc: 686.25000\n",
            "epoch: [19/50] train_loss: 0.00150 train_acc: 786.25000\n",
            "epoch: [19/50] train_loss: 0.00780 train_acc: 886.25000\n",
            "epoch: [19/50] train_loss: 0.03086 train_acc: 985.00000\n",
            "epoch: [19/50] train_loss: 0.00390 train_acc: 1085.00000\n",
            "epoch: [19/50] train_loss: 0.00030 train_acc: 1185.00000\n",
            "epoch: [19/50] train_loss: 0.00055 train_acc: 1285.00000\n",
            "epoch: [19/50] train_loss: 0.00009 train_acc: 1385.00000\n",
            "epoch: [20/50] train_loss: 0.04906 train_acc: 98.75000\n",
            "epoch: [20/50] train_loss: 0.09841 train_acc: 196.25000\n",
            "epoch: [20/50] train_loss: 0.14112 train_acc: 293.75000\n",
            "epoch: [20/50] train_loss: 0.01206 train_acc: 393.75000\n",
            "epoch: [20/50] train_loss: 0.00337 train_acc: 493.75000\n",
            "epoch: [20/50] train_loss: 0.05448 train_acc: 592.50000\n",
            "epoch: [20/50] train_loss: 0.07783 train_acc: 690.00000\n",
            "epoch: [20/50] train_loss: 0.00170 train_acc: 790.00000\n",
            "epoch: [20/50] train_loss: 0.00034 train_acc: 890.00000\n",
            "epoch: [20/50] train_loss: 0.00708 train_acc: 990.00000\n",
            "epoch: [20/50] train_loss: 0.00093 train_acc: 1090.00000\n",
            "epoch: [20/50] train_loss: 0.00012 train_acc: 1190.00000\n",
            "epoch: [20/50] train_loss: 0.00337 train_acc: 1290.00000\n",
            "epoch: [20/50] train_loss: 0.00003 train_acc: 1390.00000\n",
            "epoch: [21/50] train_loss: 1.05575 train_acc: 91.25000\n",
            "epoch: [21/50] train_loss: 0.20954 train_acc: 187.50000\n",
            "epoch: [21/50] train_loss: 0.10378 train_acc: 286.25000\n",
            "epoch: [21/50] train_loss: 0.06494 train_acc: 383.75000\n",
            "epoch: [21/50] train_loss: 0.00413 train_acc: 483.75000\n",
            "epoch: [21/50] train_loss: 0.00083 train_acc: 583.75000\n",
            "epoch: [21/50] train_loss: 0.15508 train_acc: 681.25000\n",
            "epoch: [21/50] train_loss: 0.00080 train_acc: 781.25000\n",
            "epoch: [21/50] train_loss: 0.02043 train_acc: 880.00000\n",
            "epoch: [21/50] train_loss: 0.00820 train_acc: 980.00000\n",
            "epoch: [21/50] train_loss: 0.00217 train_acc: 1080.00000\n",
            "epoch: [21/50] train_loss: 0.00023 train_acc: 1180.00000\n",
            "epoch: [21/50] train_loss: 0.00598 train_acc: 1280.00000\n",
            "epoch: [21/50] train_loss: 0.00004 train_acc: 1380.00000\n",
            "epoch: [22/50] train_loss: 0.00650 train_acc: 100.00000\n",
            "epoch: [22/50] train_loss: 0.00319 train_acc: 200.00000\n",
            "epoch: [22/50] train_loss: 0.00148 train_acc: 300.00000\n",
            "epoch: [22/50] train_loss: 0.00025 train_acc: 400.00000\n",
            "epoch: [22/50] train_loss: 0.00015 train_acc: 500.00000\n",
            "epoch: [22/50] train_loss: 0.00054 train_acc: 600.00000\n",
            "epoch: [22/50] train_loss: 0.00226 train_acc: 700.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 800.00000\n",
            "epoch: [22/50] train_loss: 0.00168 train_acc: 900.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 1000.00000\n",
            "epoch: [22/50] train_loss: 0.00017 train_acc: 1100.00000\n",
            "epoch: [22/50] train_loss: 0.00001 train_acc: 1200.00000\n",
            "epoch: [22/50] train_loss: 0.00007 train_acc: 1300.00000\n",
            "epoch: [22/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [23/50] train_loss: 0.00033 train_acc: 100.00000\n",
            "epoch: [23/50] train_loss: 0.00004 train_acc: 200.00000\n",
            "epoch: [23/50] train_loss: 0.00010 train_acc: 300.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [23/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [23/50] train_loss: 0.00168 train_acc: 600.00000\n",
            "epoch: [23/50] train_loss: 0.00172 train_acc: 700.00000\n",
            "epoch: [23/50] train_loss: 0.00058 train_acc: 800.00000\n",
            "epoch: [23/50] train_loss: 0.00129 train_acc: 900.00000\n",
            "epoch: [23/50] train_loss: 0.00002 train_acc: 1000.00000\n",
            "epoch: [23/50] train_loss: 0.00003 train_acc: 1100.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [23/50] train_loss: 0.00007 train_acc: 1300.00000\n",
            "epoch: [23/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [24/50] train_loss: 0.00011 train_acc: 100.00000\n",
            "epoch: [24/50] train_loss: 0.02024 train_acc: 198.75000\n",
            "epoch: [24/50] train_loss: 0.56002 train_acc: 293.75000\n",
            "epoch: [24/50] train_loss: 0.05128 train_acc: 392.50000\n",
            "epoch: [24/50] train_loss: 0.00101 train_acc: 492.50000\n",
            "epoch: [24/50] train_loss: 0.06020 train_acc: 591.25000\n",
            "epoch: [24/50] train_loss: 0.02361 train_acc: 690.00000\n",
            "epoch: [24/50] train_loss: 0.00013 train_acc: 790.00000\n",
            "epoch: [24/50] train_loss: 0.03135 train_acc: 887.50000\n",
            "epoch: [24/50] train_loss: 0.00207 train_acc: 987.50000\n",
            "epoch: [24/50] train_loss: 0.00087 train_acc: 1087.50000\n",
            "epoch: [24/50] train_loss: 0.00002 train_acc: 1187.50000\n",
            "epoch: [24/50] train_loss: 0.00148 train_acc: 1287.50000\n",
            "epoch: [24/50] train_loss: 0.00040 train_acc: 1387.50000\n",
            "epoch: [25/50] train_loss: 0.00077 train_acc: 100.00000\n",
            "epoch: [25/50] train_loss: 0.00659 train_acc: 200.00000\n",
            "epoch: [25/50] train_loss: 0.16432 train_acc: 297.50000\n",
            "epoch: [25/50] train_loss: 0.01704 train_acc: 396.25000\n",
            "epoch: [25/50] train_loss: 0.00020 train_acc: 496.25000\n",
            "epoch: [25/50] train_loss: 0.09742 train_acc: 595.00000\n",
            "epoch: [25/50] train_loss: 0.02195 train_acc: 693.75000\n",
            "epoch: [25/50] train_loss: 0.00009 train_acc: 793.75000\n",
            "epoch: [25/50] train_loss: 0.07648 train_acc: 891.25000\n",
            "epoch: [25/50] train_loss: 0.00543 train_acc: 991.25000\n",
            "epoch: [25/50] train_loss: 0.00178 train_acc: 1091.25000\n",
            "epoch: [25/50] train_loss: 0.00001 train_acc: 1191.25000\n",
            "epoch: [25/50] train_loss: 0.00218 train_acc: 1291.25000\n",
            "epoch: [25/50] train_loss: 0.00111 train_acc: 1391.25000\n",
            "epoch: [26/50] train_loss: 0.00063 train_acc: 100.00000\n",
            "epoch: [26/50] train_loss: 0.02170 train_acc: 198.75000\n",
            "epoch: [26/50] train_loss: 0.36556 train_acc: 295.00000\n",
            "epoch: [26/50] train_loss: 0.06984 train_acc: 392.50000\n",
            "epoch: [26/50] train_loss: 0.00392 train_acc: 492.50000\n",
            "epoch: [26/50] train_loss: 0.00396 train_acc: 592.50000\n",
            "epoch: [26/50] train_loss: 0.00137 train_acc: 692.50000\n",
            "epoch: [26/50] train_loss: 0.07357 train_acc: 790.00000\n",
            "epoch: [26/50] train_loss: 1.16475 train_acc: 886.25000\n",
            "epoch: [26/50] train_loss: 0.08174 train_acc: 985.00000\n",
            "epoch: [26/50] train_loss: 0.02746 train_acc: 1083.75000\n",
            "epoch: [26/50] train_loss: 0.00014 train_acc: 1183.75000\n",
            "epoch: [26/50] train_loss: 0.00715 train_acc: 1283.75000\n",
            "epoch: [26/50] train_loss: 0.00358 train_acc: 1383.75000\n",
            "epoch: [27/50] train_loss: 0.00198 train_acc: 100.00000\n",
            "epoch: [27/50] train_loss: 0.00312 train_acc: 200.00000\n",
            "epoch: [27/50] train_loss: 0.00159 train_acc: 300.00000\n",
            "epoch: [27/50] train_loss: 0.00055 train_acc: 400.00000\n",
            "epoch: [27/50] train_loss: 0.00265 train_acc: 500.00000\n",
            "epoch: [27/50] train_loss: 0.00011 train_acc: 600.00000\n",
            "epoch: [27/50] train_loss: 0.00178 train_acc: 700.00000\n",
            "epoch: [27/50] train_loss: 0.03442 train_acc: 798.75000\n",
            "epoch: [27/50] train_loss: 0.01483 train_acc: 897.50000\n",
            "epoch: [27/50] train_loss: 0.00152 train_acc: 997.50000\n",
            "epoch: [27/50] train_loss: 0.00160 train_acc: 1097.50000\n",
            "epoch: [27/50] train_loss: 0.00001 train_acc: 1197.50000\n",
            "epoch: [27/50] train_loss: 0.03805 train_acc: 1296.25000\n",
            "epoch: [27/50] train_loss: 0.00633 train_acc: 1396.25000\n",
            "epoch: [28/50] train_loss: 0.00274 train_acc: 100.00000\n",
            "epoch: [28/50] train_loss: 0.01764 train_acc: 198.75000\n",
            "epoch: [28/50] train_loss: 0.00243 train_acc: 298.75000\n",
            "epoch: [28/50] train_loss: 0.00084 train_acc: 398.75000\n",
            "epoch: [28/50] train_loss: 0.01973 train_acc: 497.50000\n",
            "epoch: [28/50] train_loss: 0.02526 train_acc: 596.25000\n",
            "epoch: [28/50] train_loss: 0.39142 train_acc: 692.50000\n",
            "epoch: [28/50] train_loss: 0.01525 train_acc: 791.25000\n",
            "epoch: [28/50] train_loss: 0.00240 train_acc: 891.25000\n",
            "epoch: [28/50] train_loss: 0.01527 train_acc: 990.00000\n",
            "epoch: [28/50] train_loss: 0.00154 train_acc: 1090.00000\n",
            "epoch: [28/50] train_loss: 0.00008 train_acc: 1190.00000\n",
            "epoch: [28/50] train_loss: 0.00332 train_acc: 1290.00000\n",
            "epoch: [28/50] train_loss: 0.00010 train_acc: 1390.00000\n",
            "epoch: [29/50] train_loss: 0.00136 train_acc: 100.00000\n",
            "epoch: [29/50] train_loss: 0.00331 train_acc: 200.00000\n",
            "epoch: [29/50] train_loss: 0.02724 train_acc: 298.75000\n",
            "epoch: [29/50] train_loss: 0.00144 train_acc: 398.75000\n",
            "epoch: [29/50] train_loss: 0.00147 train_acc: 498.75000\n",
            "epoch: [29/50] train_loss: 0.00013 train_acc: 598.75000\n",
            "epoch: [29/50] train_loss: 0.00277 train_acc: 698.75000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 798.75000\n",
            "epoch: [29/50] train_loss: 0.00018 train_acc: 898.75000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 998.75000\n",
            "epoch: [29/50] train_loss: 0.00005 train_acc: 1098.75000\n",
            "epoch: [29/50] train_loss: 0.00001 train_acc: 1198.75000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1298.75000\n",
            "epoch: [29/50] train_loss: 0.00000 train_acc: 1398.75000\n",
            "epoch: [30/50] train_loss: 0.00023 train_acc: 100.00000\n",
            "epoch: [30/50] train_loss: 0.00009 train_acc: 200.00000\n",
            "epoch: [30/50] train_loss: 0.00024 train_acc: 300.00000\n",
            "epoch: [30/50] train_loss: 0.00006 train_acc: 400.00000\n",
            "epoch: [30/50] train_loss: 0.00006 train_acc: 500.00000\n",
            "epoch: [30/50] train_loss: 0.00003 train_acc: 600.00000\n",
            "epoch: [30/50] train_loss: 0.00048 train_acc: 700.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [30/50] train_loss: 0.00019 train_acc: 900.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [30/50] train_loss: 0.00007 train_acc: 1100.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [30/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [31/50] train_loss: 0.00002 train_acc: 100.00000\n",
            "epoch: [31/50] train_loss: 0.00003 train_acc: 200.00000\n",
            "epoch: [31/50] train_loss: 0.00004 train_acc: 300.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 400.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 500.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 600.00000\n",
            "epoch: [31/50] train_loss: 0.00013 train_acc: 700.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [31/50] train_loss: 0.00001 train_acc: 900.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [31/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [32/50] train_loss: 0.00002 train_acc: 300.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [32/50] train_loss: 0.00004 train_acc: 700.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [32/50] train_loss: 0.00001 train_acc: 900.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [32/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [33/50] train_loss: 0.00001 train_acc: 300.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [33/50] train_loss: 0.00002 train_acc: 700.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [33/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [34/50] train_loss: 0.00001 train_acc: 700.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [34/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [35/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [36/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [37/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [38/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [39/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [40/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [41/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [42/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [43/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [44/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [45/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [46/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [47/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [48/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [49/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 100.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 200.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 300.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 400.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 500.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 600.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 700.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 800.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 900.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1000.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1100.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1200.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1300.00000\n",
            "epoch: [50/50] train_loss: 0.00000 train_acc: 1400.00000\n",
            "learning finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    total_acc = 0.0\n",
        "    acc = 0.0\n",
        "    data = x_test.to('cuda')\n",
        "    labels = y_test.to('cuda')\n",
        "\n",
        "    for i,data in enumerate(x_test, 0):\n",
        "        data = data.to('cuda')\n",
        "        labels = y_test.to('cuda')\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        acc = accuracy(outputs, k)\n",
        "        total_acc += acc\n",
        "\n",
        "        count = i\n",
        "\n",
        "    print('avarage acc: %.5f' % (total_acc/count),'%')\n",
        "\n",
        "print('test finish!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfdAH83e-LS-",
        "outputId": "fe5bc8c5-51c1-4f9b-942f-ffb5d01d2e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avarage acc: 99.65398 %\n",
            "test finish!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예측성능이 제일 좋아진 것 같다"
      ],
      "metadata": {
        "id": "uyZTlLE7_lzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 커널 사이즈를 바꿔보자"
      ],
      "metadata": {
        "id": "JekQsMEAoLAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(2304, 512) \n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = x.reshape(-1, 2304)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model.to('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "1Ya19_3B_qj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i,data in enumerate(x_train, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to('cuda')\n",
        "        labels = y_train.to('cuda')\n",
        "\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        #print(\"intpus_1 shape: \",input_1.shape)\n",
        "        #print(\"outputs shape: \",outputs.shape)\n",
        "        #print(\"labels shape\",labels.shape)\n",
        "         #labels = labels.view(len(labels),-1)\n",
        "        loss = criterion(outputs, k)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += accuracy(outputs, k)\n",
        "\n",
        "        if i % 1120 == 1119:\n",
        "            print('epoch: [%d/%d] train_loss: %.3f train_acc: %.3f' % (\n",
        "                epoch + 1, epochs, running_loss / 1120, running_acc / 1120))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"learning finish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ynghG47oSB6",
        "outputId": "effa2fc2-01a7-4676-8a94-6abff440b3dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/30] train_loss: 0.300 train_acc: 85.982\n",
            "epoch: [2/30] train_loss: 0.144 train_acc: 94.911\n",
            "epoch: [3/30] train_loss: 0.094 train_acc: 96.518\n",
            "epoch: [4/30] train_loss: 0.065 train_acc: 97.946\n",
            "epoch: [5/30] train_loss: 0.059 train_acc: 98.482\n",
            "epoch: [6/30] train_loss: 0.040 train_acc: 98.482\n",
            "epoch: [7/30] train_loss: 0.021 train_acc: 99.286\n",
            "epoch: [8/30] train_loss: 0.030 train_acc: 98.750\n",
            "epoch: [9/30] train_loss: 0.026 train_acc: 99.196\n",
            "epoch: [10/30] train_loss: 0.022 train_acc: 99.375\n",
            "epoch: [11/30] train_loss: 0.016 train_acc: 99.196\n",
            "epoch: [12/30] train_loss: 0.028 train_acc: 99.464\n",
            "epoch: [13/30] train_loss: 0.007 train_acc: 99.732\n",
            "epoch: [14/30] train_loss: 0.007 train_acc: 99.911\n",
            "epoch: [15/30] train_loss: 0.007 train_acc: 99.732\n",
            "epoch: [16/30] train_loss: 0.004 train_acc: 99.911\n",
            "epoch: [17/30] train_loss: 0.017 train_acc: 99.643\n",
            "epoch: [18/30] train_loss: 0.010 train_acc: 99.732\n",
            "epoch: [19/30] train_loss: 0.001 train_acc: 100.000\n",
            "epoch: [20/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [21/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [22/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [23/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [24/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [25/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [26/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [27/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [28/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [29/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [30/30] train_loss: 0.000 train_acc: 100.000\n",
            "learning finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    total_acc = 0.0\n",
        "    acc = 0.0\n",
        "    data = x_test.to('cuda')\n",
        "    labels = y_test.to('cuda')\n",
        "\n",
        "    for i,data in enumerate(x_test, 0):\n",
        "        data = data.to('cuda')\n",
        "        labels = y_test.to('cuda')\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        acc = accuracy(outputs, k)\n",
        "        total_acc += acc\n",
        "\n",
        "        count = i\n",
        "\n",
        "    print('avarage acc: %.5f' % (total_acc/count),'%')\n",
        "\n",
        "print('test finish!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjTVSVAYpN11",
        "outputId": "469517e9-c00d-4d84-fc71-52d15ea3623b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avarage acc: 97.92388 %\n",
            "test finish!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패딩의 여부"
      ],
      "metadata": {
        "id": "lcTzJkt3s2vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=1)\n",
        "        self.fc1 = nn.Linear(1024, 512) \n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = x.reshape(-1, 1024)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model.to('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "SaZOTeWks7vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "x = torch.ones([1,3,64,64])\n",
        "conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1)\n",
        "output1 = conv1(x)\n",
        "print(output1.shape)\n",
        "x1 = F.max_pool2d(F.relu(output1),2)\n",
        "print(x1.shape)\n",
        "conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1)\n",
        "output2 = conv2(x1)\n",
        "print(output2.shape)\n",
        "x2 = F.max_pool2d(F.relu(output2), 2)\n",
        "print(x2.shape)\n",
        "conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=1)\n",
        "output3 = conv3(x2)\n",
        "print(output3.shape)\n",
        "x3 = F.max_pool2d(F.relu(output3), 2)\n",
        "print(x3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJAbwQQHsymn",
        "outputId": "146766c4-c8aa-4e16-e5e5-186d7682f5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 60, 60])\n",
            "torch.Size([1, 16, 30, 30])\n",
            "torch.Size([1, 32, 26, 26])\n",
            "torch.Size([1, 32, 13, 13])\n",
            "torch.Size([1, 64, 9, 9])\n",
            "torch.Size([1, 64, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i,data in enumerate(x_train, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to('cuda')\n",
        "        labels = y_train.to('cuda')\n",
        "\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        #print(\"intpus_1 shape: \",input_1.shape)\n",
        "        #print(\"outputs shape: \",outputs.shape)\n",
        "        #print(\"labels shape\",labels.shape)\n",
        "         #labels = labels.view(len(labels),-1)\n",
        "        loss = criterion(outputs, k)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += accuracy(outputs, k)\n",
        "\n",
        "        if i % 1120 == 1119:\n",
        "            print('epoch: [%d/%d] train_loss: %.3f train_acc: %.3f' % (\n",
        "                epoch + 1, epochs, running_loss / 1120, running_acc / 1120))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"learning finish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBzk26TAtARY",
        "outputId": "cd0cd96d-d7e0-4b43-9563-76f57b4a22d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/30] train_loss: 0.294 train_acc: 86.161\n",
            "epoch: [2/30] train_loss: 0.132 train_acc: 95.625\n",
            "epoch: [3/30] train_loss: 0.094 train_acc: 96.607\n",
            "epoch: [4/30] train_loss: 0.077 train_acc: 96.875\n",
            "epoch: [5/30] train_loss: 0.066 train_acc: 97.589\n",
            "epoch: [6/30] train_loss: 0.046 train_acc: 98.036\n",
            "epoch: [7/30] train_loss: 0.034 train_acc: 98.750\n",
            "epoch: [8/30] train_loss: 0.023 train_acc: 99.107\n",
            "epoch: [9/30] train_loss: 0.039 train_acc: 98.750\n",
            "epoch: [10/30] train_loss: 0.020 train_acc: 99.286\n",
            "epoch: [11/30] train_loss: 0.015 train_acc: 99.643\n",
            "epoch: [12/30] train_loss: 0.015 train_acc: 99.286\n",
            "epoch: [13/30] train_loss: 0.021 train_acc: 99.375\n",
            "epoch: [14/30] train_loss: 0.005 train_acc: 100.000\n",
            "epoch: [15/30] train_loss: 0.005 train_acc: 99.911\n",
            "epoch: [16/30] train_loss: 0.009 train_acc: 99.821\n",
            "epoch: [17/30] train_loss: 0.011 train_acc: 99.554\n",
            "epoch: [18/30] train_loss: 0.004 train_acc: 99.821\n",
            "epoch: [19/30] train_loss: 0.016 train_acc: 99.643\n",
            "epoch: [20/30] train_loss: 0.001 train_acc: 100.000\n",
            "epoch: [21/30] train_loss: 0.001 train_acc: 100.000\n",
            "epoch: [22/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [23/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [24/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [25/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [26/30] train_loss: 0.000 train_acc: 100.000\n",
            "epoch: [27/30] train_loss: 0.027 train_acc: 99.464\n",
            "epoch: [28/30] train_loss: 0.015 train_acc: 99.554\n",
            "epoch: [29/30] train_loss: 0.001 train_acc: 100.000\n",
            "epoch: [30/30] train_loss: 0.001 train_acc: 100.000\n",
            "learning finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    total_acc = 0.0\n",
        "    acc = 0.0\n",
        "    data = x_test.to('cuda')\n",
        "    labels = y_test.to('cuda')\n",
        "\n",
        "    for i,data in enumerate(x_test, 0):\n",
        "        data = data.to('cuda')\n",
        "        labels = y_test.to('cuda')\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        acc = accuracy(outputs, k)\n",
        "        total_acc += acc\n",
        "\n",
        "        count = i\n",
        "\n",
        "    print('avarage acc: %.5f' % (total_acc/count),'%')\n",
        "\n",
        "print('test finish!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wDCNbMAtHr1",
        "outputId": "46a94d68-4af7-421c-ada9-790f8c7fa456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avarage acc: 98.96194 %\n",
            "test finish!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**yawn/ no yawn**"
      ],
      "metadata": {
        "id": "I4Fbk2yz8Ie9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path=\"/content/drive/MyDrive/2기 딥러닝 프로젝트/train\"\n",
        "labels = ['no_yawn', 'yawn']\n",
        "x_data = []\n",
        "y_data = []\n",
        "for label in labels:\n",
        "   path = os.path.join(dir_path, label)\n",
        "   class_num = labels.index(label)\n",
        "   import torchvision.transforms as transforms\n",
        "   tf = transforms.ToTensor()\n",
        "   for img in os.listdir(path): # closed 폴더 안에 _1.jpg, open 폴더 안에 1.jpg \n",
        "       paths = os.path.join(path, img)\n",
        "       img =  PIL.Image.open(paths)\n",
        "       re_img = img.resize((64,64))\n",
        "       re_img = tf(re_img)\n",
        "       re_img = re_img.tolist()\n",
        "       if len(re_img) == 3:\n",
        "         x_data.append(re_img)\n",
        "         y_data.append(class_num)\n",
        "\n",
        "x_data = torch.tensor(x_data)\n",
        "y_data = torch.tensor(y_data)"
      ],
      "metadata": {
        "id": "r4sHG_B7unQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag2-fmGi-Qp7",
        "outputId": "45bbffd9-349b-4703-e627-0c1ca17f4703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1448])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Xxr1GccP93Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i,data in enumerate(x_train, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to('cuda')\n",
        "        labels = y_train.to('cuda')\n",
        "\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        #print(\"intpus_1 shape: \",input_1.shape)\n",
        "        #print(\"outputs shape: \",outputs.shape)\n",
        "        #print(\"labels shape\",labels.shape)\n",
        "         #labels = labels.view(len(labels),-1)\n",
        "        loss = criterion(outputs, k)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += accuracy(outputs, k)\n",
        "\n",
        "        if i % 1120 == 1119:\n",
        "            print('epoch: [%d/%d] train_loss: %.3f train_acc: %.3f' % (\n",
        "                epoch + 1, epochs, running_loss / 1120, running_acc / 1120))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"learning finish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VRdUgbY-koM",
        "outputId": "1b859638-33c1-483e-bf31-d770626569e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/30] train_loss: 0.620 train_acc: 61.607\n",
            "epoch: [2/30] train_loss: 0.566 train_acc: 67.054\n",
            "epoch: [3/30] train_loss: 0.551 train_acc: 69.196\n",
            "epoch: [4/30] train_loss: 0.532 train_acc: 72.232\n",
            "epoch: [5/30] train_loss: 0.508 train_acc: 74.464\n",
            "epoch: [6/30] train_loss: 0.480 train_acc: 77.232\n",
            "epoch: [7/30] train_loss: 0.449 train_acc: 78.839\n",
            "epoch: [8/30] train_loss: 0.416 train_acc: 81.518\n",
            "epoch: [9/30] train_loss: 0.380 train_acc: 83.482\n",
            "epoch: [10/30] train_loss: 0.341 train_acc: 85.625\n",
            "epoch: [11/30] train_loss: 0.298 train_acc: 88.125\n",
            "epoch: [12/30] train_loss: 0.256 train_acc: 90.089\n",
            "epoch: [13/30] train_loss: 0.216 train_acc: 91.786\n",
            "epoch: [14/30] train_loss: 0.179 train_acc: 93.929\n",
            "epoch: [15/30] train_loss: 0.145 train_acc: 95.357\n",
            "epoch: [16/30] train_loss: 0.118 train_acc: 96.696\n",
            "epoch: [17/30] train_loss: 0.098 train_acc: 97.054\n",
            "epoch: [18/30] train_loss: 0.080 train_acc: 97.679\n",
            "epoch: [19/30] train_loss: 0.066 train_acc: 98.214\n",
            "epoch: [20/30] train_loss: 0.057 train_acc: 98.125\n",
            "epoch: [21/30] train_loss: 0.047 train_acc: 98.839\n",
            "epoch: [22/30] train_loss: 0.046 train_acc: 98.571\n",
            "epoch: [23/30] train_loss: 0.034 train_acc: 99.286\n",
            "epoch: [24/30] train_loss: 0.031 train_acc: 98.929\n",
            "epoch: [25/30] train_loss: 0.041 train_acc: 98.304\n",
            "epoch: [26/30] train_loss: 0.020 train_acc: 99.286\n",
            "epoch: [27/30] train_loss: 0.029 train_acc: 99.196\n",
            "epoch: [28/30] train_loss: 0.026 train_acc: 99.286\n",
            "epoch: [29/30] train_loss: 0.032 train_acc: 98.839\n",
            "epoch: [30/30] train_loss: 0.011 train_acc: 99.821\n",
            "learning finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    total_acc = 0.0\n",
        "    acc = 0.0\n",
        "    data = x_test.to('cuda')\n",
        "    labels = y_test.to('cuda')\n",
        "\n",
        "    for i,data in enumerate(x_test, 0):\n",
        "        data = data.to('cuda')\n",
        "        labels = y_test.to('cuda')\n",
        "        k = torch.tensor(labels[i])\n",
        "        k = k.view(1,-1)\n",
        "        k = k.float()\n",
        "        k = k.to('cuda')\n",
        "        outputs = model(data)\n",
        "        acc = accuracy(outputs, k)\n",
        "        total_acc += acc\n",
        "\n",
        "        count = i\n",
        "\n",
        "    print('avarage acc: %.5f' % (total_acc/count),'%')\n",
        "\n",
        "print('test finish!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4DZy1QU-l0O",
        "outputId": "8a2e50c8-7b2e-45c4-98a5-588d266afe18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avarage acc: 94.80969 %\n",
            "test finish!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbYU6q0T_zUn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}